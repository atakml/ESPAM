{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62259ee",
   "metadata": {},
   "source": [
    "# Initilization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89a9bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model obtained: Train Acc: 0.8811, Val Acc: 0.8415, Test Acc: 0.8232.\n",
      "Loading BBBP dataset\n",
      "torch.Size([1312, 133, 13]) torch.Size([1312, 2]) 1312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1378602/145080924.py:37: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  features = torch.tensor(features)\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from ExplanationEvaluation.models.model_selector import model_selector\n",
    "from ExplanationEvaluation.configs.selector import Selector\n",
    "from ExplanationEvaluation.datasets.dataset_loaders import load_dataset\n",
    "from ExplanationEvaluation.tasks.replication import get_classification_task, to_torch_graph\n",
    "\n",
    "\n",
    "dataset_name = \"bbbp\"\n",
    "\n",
    "# Load pretrained models\n",
    "_dataset = \"bbbp\"\n",
    "_explainer = \"actexplainer\"\n",
    "\n",
    "_folder = 'replication' # One of: replication, extension\n",
    "\n",
    "config_path = f\"GNN-explain/codebase/ExplanationEvaluation/configs/{_folder}/explainers/{_explainer}/{_dataset}.json\"\n",
    "radius = 3\n",
    "config = Selector(config_path)\n",
    "config = config.args.explainer\n",
    "model, checkpoint = model_selector(config.model,\n",
    "                                    config.dataset,\n",
    "                                    pretrained=True,\n",
    "                                    return_checkpoint=True)\n",
    "if config.eval_enabled:\n",
    "    model.eval()\n",
    "    \n",
    "graphs, features, labels, train_mask, _, test_mask = load_dataset(config.dataset)\n",
    "task = get_classification_task(graphs)\n",
    "\n",
    "graphs = [g for i, g in enumerate(graphs) if train_mask[i]]\n",
    "features = [f for i, f in enumerate(features) if train_mask[i]]\n",
    "labels = [l for i, l in enumerate(labels) if train_mask[i]]\n",
    "\n",
    "\n",
    "features = torch.tensor(features)\n",
    "labels = torch.tensor(labels)\n",
    "graphs = to_torch_graph(graphs, task)\n",
    "print(features.shape, labels.shape, len(graphs))\n",
    "dataset = [Data(x=features[i], edge_index=graphs[i], y=labels[i]) for i in range(len(graphs))]\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569aea5b",
   "metadata": {},
   "source": [
    "# ESPAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4664bc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relable_nodes(feature, edge_index, node_subset):\n",
    "    node_subset = torch.unique(node_subset, return_inverse=True, sorted=True)\n",
    "    node_dict = {node_subset[0][i].item(): node_subset[1][i].item() for i in range(node_subset[0].shape[0])}\n",
    "    edge_index = torch.tensor([[node_dict[u.item()], node_dict[v.item()]] for u, v in edge_index.T]).T\n",
    "    return feature[node_subset[0]], edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2be31e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from torch_geometric.utils import k_hop_subgraph, mask_to_index, index_to_mask\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "def features_to_graph(data,z,l):\n",
    "    center_nodes = []\n",
    "    for i in range(len(z)):\n",
    "        if(z[i] == 0):\n",
    "            center_nodes.append(i)\n",
    "           \n",
    "    kh_subset, kh_edge_index, kh_mapping, kh_edge_mask = k_hop_subgraph1(center_nodes, l, data.edge_index, \n",
    "                                                                                relabel_nodes=False)\n",
    "    g = dgl.graph((data.edge_index[0], data.edge_index[1]))\n",
    "    #print(type(g))\n",
    "    #hub_ego = nx.ego_graph(g, center_nodes[0])\n",
    "    #print(type(hub_ego), type(g))\n",
    "    ''''\n",
    "    #print('nodes',kh_subset)\n",
    "    #remove edges\n",
    "    remove_edges = []\n",
    "    for j in range(len(center_nodes)):\n",
    "        for i in range(len(data.edge_index[0])):\n",
    "            if((data.edge_index[0][i] == center_nodes[j]) or (data.edge_index[1][i] == center_nodes[j])):\n",
    "                remove_edges.append(i)\n",
    "    #end remove edges\n",
    "    #print(remove_edges)\n",
    "    #to_be_remove = torch.logical_and(to_be_remove,torch.logical_not(kh_edge_mask))\n",
    "    #print('tbr',to_be_remove)\n",
    "    #if(r):\n",
    "    g.remove_edges(remove_edges) ###mask_to_index(kh_edge_mask))\n",
    "    '''\n",
    "    \n",
    "    g.remove_edges(mask_to_index(kh_edge_mask))\n",
    "    \n",
    "    \n",
    "    edges_src, edges_dst = g.edges()\n",
    "    #print(data.num_nodes, data.num_edges)\n",
    "    edge_index = torch.tensor([edges_src.numpy(), edges_dst.numpy()], dtype=torch.long)\n",
    "    data = Data(x=data.x, edge_index=edge_index)#, y=data.y, shape=data.shape)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98753c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khop\n",
    "\n",
    "\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.typing import OptTensor, PairTensor\n",
    "\n",
    "from torch_geometric.utils.mask import index_to_mask\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "\n",
    "def k_hop_subgraph1(\n",
    "    node_idx: Union[int, List[int], Tensor],\n",
    "    num_hops: int,\n",
    "    edge_index: Tensor,\n",
    "    relabel_nodes: bool = False,\n",
    "    num_nodes: Optional[int] = None,\n",
    "    flow: str = 'source_to_target',\n",
    "    directed: bool = False,\n",
    ") -> Tuple[Tensor, Tensor, Tensor, Tensor]:\n",
    "    r\"\"\"Computes the induced subgraph of :obj:`edge_index` around all nodes in\n",
    "    :attr:`node_idx` reachable within :math:`k` hops.\n",
    "\n",
    "    The :attr:`flow` argument denotes the direction of edges for finding\n",
    "    :math:`k`-hop neighbors. If set to :obj:`\"source_to_target\"`, then the\n",
    "    method will find all neighbors that point to the initial set of seed nodes\n",
    "    in :attr:`node_idx.`\n",
    "    This mimics the natural flow of message passing in Graph Neural Networks.\n",
    "\n",
    "    The method returns (1) the nodes involved in the subgraph, (2) the filtered\n",
    "    :obj:`edge_index` connectivity, (3) the mapping from node indices in\n",
    "    :obj:`node_idx` to their new location, and (4) the edge mask indicating\n",
    "    which edges were preserved.\n",
    "\n",
    "    Args:\n",
    "        node_idx (int, list, tuple or :obj:`torch.Tensor`): The central seed\n",
    "            node(s).\n",
    "        num_hops (int): The number of hops :math:`k`.\n",
    "        edge_index (LongTensor): The edge indices.\n",
    "        relabel_nodes (bool, optional): If set to :obj:`True`, the resulting\n",
    "            :obj:`edge_index` will be relabeled to hold consecutive indices\n",
    "            starting from zero. (default: :obj:`False`)\n",
    "        num_nodes (int, optional): The number of nodes, *i.e.*\n",
    "            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)\n",
    "        flow (str, optional): The flow direction of :math:`k`-hop aggregation\n",
    "            (:obj:`\"source_to_target\"` or :obj:`\"target_to_source\"`).\n",
    "            (default: :obj:`\"source_to_target\"`)\n",
    "        directed (bool, optional): If set to :obj:`False`, will include all\n",
    "            edges between all sampled nodes. (default: :obj:`True`)\n",
    "\n",
    "    :rtype: (:class:`LongTensor`, :class:`LongTensor`, :class:`LongTensor`,\n",
    "             :class:`BoolTensor`)\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        >>> edge_index = torch.tensor([[0, 1, 2, 3, 4, 5],\n",
    "        ...                            [2, 2, 4, 4, 6, 6]])\n",
    "\n",
    "        >>> # Center node 6, 2-hops\n",
    "        >>> subset, edge_index, mapping, edge_mask = k_hop_subgraph(\n",
    "        ...     6, 2, edge_index, relabel_nodes=True)\n",
    "        >>> subset\n",
    "        tensor([2, 3, 4, 5, 6])\n",
    "        >>> edge_index\n",
    "        tensor([[0, 1, 2, 3],\n",
    "                [2, 2, 4, 4]])\n",
    "        >>> mapping\n",
    "        tensor([4])\n",
    "        >>> edge_mask\n",
    "        tensor([False, False,  True,  True,  True,  True])\n",
    "        >>> subset[mapping]\n",
    "        tensor([6])\n",
    "\n",
    "        >>> edge_index = torch.tensor([[1, 2, 4, 5],\n",
    "        ...                            [0, 1, 5, 6]])\n",
    "        >>> (subset, edge_index,\n",
    "        ...  mapping, edge_mask) = k_hop_subgraph([0, 6], 2,\n",
    "        ...                                       edge_index,\n",
    "        ...                                       relabel_nodes=True)\n",
    "        >>> subset\n",
    "        tensor([0, 1, 2, 4, 5, 6])\n",
    "        >>> edge_index\n",
    "        tensor([[1, 2, 3, 4],\n",
    "                [0, 1, 4, 5]])\n",
    "        >>> mapping\n",
    "        tensor([0, 5])\n",
    "        >>> edge_mask\n",
    "        tensor([True, True, True, True])\n",
    "        >>> subset[mapping]\n",
    "        tensor([0, 6])\n",
    "    \"\"\"\n",
    "    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
    "\n",
    "    assert flow in ['source_to_target', 'target_to_source']\n",
    "    if flow == 'target_to_source':\n",
    "        row, col = edge_index\n",
    "    else:\n",
    "        col, row = edge_index\n",
    "\n",
    "    node_mask = row.new_empty(num_nodes, dtype=torch.bool)\n",
    "    edge_mask = row.new_empty(row.size(0), dtype=torch.bool)\n",
    "     \n",
    "    #print(\"edge\")\n",
    "    #print(col)\n",
    "    #print(row)\n",
    "    \n",
    "    if isinstance(node_idx, (int, list, tuple)):\n",
    "        node_idx = torch.tensor([node_idx], device=row.device).flatten()\n",
    "    else:\n",
    "        node_idx = node_idx.to(row.device)\n",
    "\n",
    "    subsets = [node_idx]\n",
    "    tmp_subset = []\n",
    "    for i in range(num_hops):\n",
    "        node_mask.fill_(False)\n",
    "        try:\n",
    "            node_mask[subsets[-1]] = True\n",
    "        except:\n",
    "            print(node_mask)\n",
    "            print(len(node_mask))\n",
    "            print(subsets)\n",
    "            print(subsets[-1])\n",
    "            raise\n",
    "        torch.index_select(node_mask, 0, row, out=edge_mask)\n",
    "        if(i < num_hops-1): ### j'ai ajoute ce test pour enlever la derniere couronne de noeuds\n",
    "            subsets.append(col[edge_mask])\n",
    "        else:\n",
    "            tmp_subset.append(col[edge_mask])\n",
    "\n",
    "    subset, inv = torch.cat(subsets).unique(return_inverse=True, sorted=False)\n",
    "    #print(\"moins\", subset)\n",
    "    node_mask.fill_(False)\n",
    "    node_mask[subset] = True\n",
    "    #print(\"nmsk\",node_mask)\n",
    "    \n",
    "    #print(\"emsk\",edge_mask)\n",
    "    if not directed:\n",
    "        #print(\"row\")\n",
    "        #print(node_mask[row])\n",
    "        #print(node_mask[col])\n",
    "        edge_mask = node_mask[row] | node_mask[col] ## j'ai change le & en |\n",
    "        #il suffit qu'un noeud adjacent ait ete atteind pour qu'on enleve l'arete (et non pas les deux comme avant)\n",
    "    #print(\"emsk\",edge_mask)\n",
    "    \n",
    "    edge_index = edge_index[:, edge_mask]\n",
    "    #print(\"eidx\")\n",
    "    #print(edge_index)\n",
    "    #print(inv)\n",
    "    #print(edge_mask)\n",
    "    subsets.append(tmp_subset[0])\n",
    "    subset, inv = torch.cat(subsets).unique(return_inverse=True, sorted=False)\n",
    "    inv = inv[:node_idx.numel()]\n",
    "    node_mask[subset] = True\n",
    "    \n",
    "    if relabel_nodes:\n",
    "        node_idx = row.new_full((num_nodes, ), -1)\n",
    "        node_idx[subset] = torch.arange(subset.size(0), device=row.device)\n",
    "        edge_index = node_idx[edge_index]\n",
    "    return subset, edge_index, inv, edge_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a4c1b",
   "metadata": {},
   "source": [
    "## ESPAM Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7c96f22-efb4-4b1b-b46e-5e8c8f180a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "def espam_ego_networks_average(data, model, class_index, ll=4):\n",
    "    number_of_nodes = data.x.shape[0]\n",
    "    G = to_networkx(data)\n",
    "    isolated_nodes = list(nx.isolates(G))\n",
    "    ego_sets = []\n",
    "    model_score = lambda data: model(data.x, data.edge_index)\n",
    "    graph_score = model_score(data).detach().softmax(dim=1)[0][class_index]\n",
    "    ego_contributions = []\n",
    "    complement_ego_sets = []\n",
    "    for l in range(1, ll):\n",
    "        ego_sets.append([k_hop_subgraph1(node_idx, l, data.edge_index) for node_idx in range(number_of_nodes) if node_idx not in isolated_nodes])\n",
    "        while ego_sets[-1][-1][1].shape[1] == 0:\n",
    "            print(\"!\")\n",
    "            ego_sets[-1].pop()\n",
    "            number_of_nodes -= 1\n",
    "        ego_sets[-1] = list(map(lambda x: list(relable_nodes(data.x, x[1], x[0])) + [x[2], x[3]], ego_sets[-1]))\n",
    "        complement_ego_sets.append(\n",
    "            [features_to_graph(data, torch.ones(data.x.shape[0]).scatter_(-1, torch.tensor([node_idx]), 0), l) for\n",
    "             node_idx in range(number_of_nodes) if node_idx not in isolated_nodes])\n",
    "        complement_scores = list(\n",
    "            map(lambda x: model_score(x).detach().softmax(dim=1)[0][class_index], complement_ego_sets[-1]))\n",
    "        complement_sums = sum(complement_scores)\n",
    "        try:\n",
    "            ego_scores = list(\n",
    "            map(lambda x: model_score(Data(x=x[0], edge_index=x[1])).detach().softmax(dim=1)[0][class_index], ego_sets[-1]))\n",
    "        except:\n",
    "            print(list(enumerate(map(lambda x: x[1].shape, ego_sets[-1]))))\n",
    "            print(l)\n",
    "\n",
    "            raise\n",
    "        ego_sums = sum(ego_scores)\n",
    "        w = (graph_score + complement_sums) / (complement_sums + ego_sums)\n",
    "        ego_contributions.append(list(\n",
    "            map(lambda node_index: w * ego_scores[node_index] + (1 - w) * (-complement_scores[node_index]) ,\n",
    "                range(number_of_nodes- len(isolated_nodes)))))\n",
    "    node_contributions = torch.tensor(ego_contributions).sum(dim=0) / (ll-1)\n",
    "    node_contributions = node_contributions.tolist()\n",
    "    for index in isolated_nodes:\n",
    "        node_contributions.insert(index,0)\n",
    "    return torch.tensor(node_contributions)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5600d9c3",
   "metadata": {},
   "source": [
    "## Run ESPAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1c46a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [05:20<00:00,  2.49it/s]\n"
     ]
    }
   ],
   "source": [
    "## l = 5 for BA2 and l = 2 for others has the best results\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "cnt = 0\n",
    "for l in range(2, 7):\n",
    "    espam_values = []\n",
    "    for data in tqdm(dataset):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        class_index = model(x, edge_index)[0].argmax()\n",
    "        try:\n",
    "            espam_values.append(espam_ego_networks_average(data, model, class_index, l))\n",
    "        except:\n",
    "            print(\"error\")\n",
    "            cnt += 1\n",
    "            if cnt < 3:\n",
    "                continue\n",
    "            raise\n",
    "    with open(f\"{dataset_name}_ESPAM_results_{l=}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(espam_values, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d85928e",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e82c640",
   "metadata": {},
   "source": [
    "## GNN-Explainer, GradCAM, PGExplainer, and PGM Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4af514d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [04:06<00:00,  8.21s/it]\n",
      "100%|██████████| 2000/2000 [29:38<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.explain import PGExplainer, Explainer, GNNExplainer\n",
    "from tqdm import tqdm\n",
    "from graphxai.explainers import GradCAM\n",
    "from ExplanationEvaluation.explainers.PGMExplainer import PGMExplainer\n",
    "from ExplanationEvaluation.explainers.PGExplainer import PGExplainer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "explain_dict = {}\n",
    "explainer_dict = {\"PGExplainer\":PGExplainer(model, graphs, features, task),\n",
    "    \"GNNExplainer\": Explainer(\n",
    "        model=model,\n",
    "        algorithm=GNNExplainer(),\n",
    "        explanation_type='model',\n",
    "        node_mask_type='object',\n",
    "        edge_mask_type='object',\n",
    "        model_config=dict(\n",
    "            mode='multiclass_classification',\n",
    "            task_level='graph',\n",
    "            return_type='raw',)\n",
    "            ),\n",
    "    \"GradCAM\": GradCAM(model), \n",
    "    \"PGM\": PGMExplainer(model, graphs, features, task, policy_name=None)\n",
    "}\n",
    "\n",
    "explainer_dict[\"PGExplainer\"].prepare(torch.where(torch.tensor(train_mask))[0])\n",
    "\n",
    "for i in tqdm(range(len(graphs))):\n",
    "    if not train_mask[i]:\n",
    "        continue\n",
    "    explain_dict[i] = {}\n",
    "    for explainer_name, explainer in explainer_dict.items():\n",
    "        if explainer_name == \"GNNExplainer\":\n",
    "            explain_dict[i][explainer_name] = explainer(x=features[i], edge_index=graphs[i])\n",
    "        elif explainer_name == \"GradCAM\":\n",
    "            explain_dict[i][explainer_name] = explainer.get_explanation_graph(x=features[i], edge_index=graphs[i])\n",
    "        elif explainer_name in [\"PGM\", \"PGExplainer\"]:\n",
    "            explain_dict[i][explainer_name] = explainer.explain(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ff516e",
   "metadata": {},
   "source": [
    "## GraphSVX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a883757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle \n",
    "from tqdm import tqdm \n",
    "from ExplanationEvaluation.explainers.SVXExplainer import GraphSVX\n",
    "import numpy as np\n",
    "import random \n",
    "from torch_geometric.data import Data\n",
    "device =\"cpu\"\n",
    "hfid = None\n",
    "explainer_name = \"SVX\"\n",
    "explain_dict = {}\n",
    "seed = None\n",
    "#print(explanations.keys())\n",
    "if seed is not None:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "for i in tqdm(range(len(graphs))):\n",
    "    if not train_mask[i]:\n",
    "        continue\n",
    "    explain_dict[i] = {}\n",
    "    \n",
    "    x, edge_index = features[i], graphs[i]\n",
    "    best_hfid = (0, 0,0,0)\n",
    "    svx_explainer = GraphSVX(model, [edge_index], torch.unsqueeze(x, 0), \"graph\", gpu=True)\n",
    "    svx_values = svx_explainer.explain_graphs()\n",
    "    explain_dict[i][\"SVX\"] = svx_values\n",
    "with open(f\"{_dataset}_svx_{seed}.pkl\", \"wb\") as file:\n",
    "    pickle.dump(explain_dict, file) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1945033",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1840cc03",
   "metadata": {},
   "source": [
    "### Metric Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b2e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity(data, selected_nodes, model, target_class, remove_mask_function):\n",
    "    #z = torch.ones(data.x.shape[0]).bool()\n",
    "    #z[center_indices] = False\n",
    "    x, edge_index = data.x, data.edge_index\n",
    "    complement_mask = ~selected_nodes\n",
    "    masked_graph = remove_mask_function(data, complement_mask)#features_to_graph(data, z, 1)\n",
    "    return model(x, edge_index).softmax(-1)[0][target_class] - model(masked_graph.x, masked_graph.edge_index).softmax(-1)[0][target_class]\n",
    "\n",
    "\n",
    "def infidelity(data, selected_nodes, model, target_class, remove_mask_function):\n",
    "    #z = torch.zeros(data.x.shape[0]).bool()\n",
    "    #z[center_indices] = True\n",
    "    x, edge_index = data.x, data.edge_index\n",
    "\n",
    "    complement_mask = selected_nodes\n",
    "    masked_graph = remove_mask_function(data, complement_mask)#features_to_graph(data, z, 1)\n",
    "    return model(x, edge_index).softmax(-1)[0][target_class] - model(masked_graph.x, masked_graph.edge_index).softmax(-1)[0][target_class]\n",
    "\n",
    "\n",
    "def sparsity(data, selected_nodes, remove_mask_function):\n",
    "    #data = from_smiles_to_data(smiles)\n",
    "    #z = torch.zeros(data.x.shape[0]).bool()\n",
    "    #z[center_indices] = True\n",
    "    #complement_mask = ~selected_nodes\n",
    "    #print(complement_mask)\n",
    "\n",
    "    masked_graph = remove_mask_function(data, selected_nodes)#features_to_graph(data, z, 1)\n",
    "    return 1 - (masked_graph.true_edges)/(data.edge_index.shape[1])\n",
    "\n",
    "\n",
    "def hfidelity(data, mask, model, target_class, mask_func):\n",
    "    number_of_nodes = data.x.shape[0]\n",
    "    number_of_mask_nodes = mask_func(data, mask).node_mask_size\n",
    "    fid = fidelity(data, mask, model, target_class, mask_func)\n",
    "    infid = infidelity(data, mask, model, target_class, mask_func)\n",
    "    spars = 1 -number_of_mask_nodes/number_of_nodes\n",
    "    n_fid = fid*spars\n",
    "    n_infid = infid*(1 - spars)\n",
    "    hfid = ((1 + n_fid)*(1 - n_infid))/(2+ n_fid - n_infid)\n",
    "    return hfid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346ab4b",
   "metadata": {},
   "source": [
    "### Mask Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f107465d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    cnt+= 1\\n\\nfor method in [\"ESPAM\"]:\\n    devide_metric_values(method, cnt)\\n    std_dict[method] = np.std(list(map(lambda x: x.detach().cpu().numpy(), hfid_val[method])))\\n    print(f\"{l=} {hfidelity_dict[method]} ± {std_dict[method]}\")\\n    #print(f\"protein: {protein}\\t espam hfid: {hfidelity_dict[(protein, \\'ESPAM\\')]} ± {std_dict[(protein, \\'ESPAM\\')]}\\t gstar hfid: {hfidelity_dict[(protein, \\'gstarx\\')]} ± {std_dict[(protein, \\'gstarx\\')]}\\t shap hfid: {hfidelity_dict[(protein, \\'shap\\')]} ± {std_dict[(protein, \\'shap\\')]}\")'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "\n",
    "def creat_mask_mol_data(data, mask, is_edge=False, inv=True): \n",
    "    mask = mask.to(bool)\n",
    "    x = data.x.clone()\n",
    "    edge_index = data.edge_index.clone()\n",
    "    if not is_edge:\n",
    "        if inv:\n",
    "            x[~mask] = torch.zeros_like(x[~mask])\n",
    "        else:\n",
    "            x = x[mask]\n",
    "        edge_mask = mask[edge_index[0]]&mask[edge_index[1]]\n",
    "        if inv:\n",
    "            edge_index = edge_index[:, edge_mask]\n",
    "\n",
    "        else:\n",
    "            edge_index = edge_index[:, edge_mask]\n",
    "    else:\n",
    "        edge_index = edge_index[:, mask]\n",
    "        edge_mask = mask\n",
    "        node_mask = torch.zeros(data.x.shape[0])\n",
    "        node_mask[edge_index[0]] = 1\n",
    "        node_mask[edge_index[1]] = 1\n",
    "        x[~node_mask.bool()] = torch.zeros_like(x[~node_mask.bool()])\n",
    "    res = Data(x=x, edge_index=edge_index, true_edges=sum(edge_mask), node_mask_size =node_mask.sum() if is_edge else mask.sum())\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "#####################\n",
    "#####################\n",
    "\n",
    "       \n",
    "\n",
    "def mask_compute(data, values,  model, target_class, mask_creator_function, min_sparsity):\n",
    "    number_of_nodes = data.x.shape[0]\n",
    "    G = to_networkx(data)\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    isolated_nodes = list(nx.isolates(G))\n",
    "    number_of_nodes -= len(isolated_nodes)\n",
    "    best_hfid = -100\n",
    "    fid_make_mask = lambda data, mask: creat_mask_mol_data(data, mask, inv=True)\n",
    "    for i in range(1,number_of_nodes):\n",
    "        mask = mask_creator_function(data, (values, number_of_nodes), i)\n",
    "        fid = fidelity(data, mask, model, target_class, fid_make_mask)\n",
    "        infid = infidelity(data, mask, model, target_class, fid_make_mask)\n",
    "        spars = 1 -i/data.x.shape[0]\n",
    "        if spars < min_sparsity:\n",
    "            break\n",
    "        n_fid = fid*spars\n",
    "        n_infid = infid*(1 - spars)\n",
    "        hfid = ((1 + n_fid)*(1 - n_infid))/(2+ n_fid - n_infid)\n",
    "        best_hfid = max(hfid, best_hfid)\n",
    "    return best_hfid\n",
    "\n",
    "\n",
    "\n",
    "def top_k_percent_nodes(values, k):\n",
    "    if len(values) == 2:\n",
    "        values, num_nodes = values\n",
    "    else:\n",
    "        num_nodes = 0\n",
    "    values = torch.tensor(values)\n",
    "    number_of_nodes = values.shape[0]\n",
    "    num_nodes = num_nodes if num_nodes else number_of_nodes\n",
    "    _, indices = torch.sort(values[:num_nodes], descending=True)\n",
    "    selected_indices = indices[:k]\n",
    "    mask = torch.zeros(number_of_nodes)\n",
    "    mask[selected_indices] = 1\n",
    "    return mask.to(bool)\n",
    "    \n",
    "def add_to_metrics_dict(data, values, mask_creator_function, model, target_class, method):\n",
    "    best_hfid = mask_compute(data, values, model, target_class, mask_creator_function, 0.5)\n",
    "    hfidelity_dict[method] += best_hfid\n",
    "    hfid_val[method].append(best_hfid)\n",
    "\n",
    "    \n",
    "    \n",
    "def devide_metric_values(method, cnt):\n",
    "    hfidelity_dict[method] /= cnt\n",
    "\n",
    "\n",
    "hfidelity_dict = {}\n",
    "hfid_val = {method: [] for method in [\"ESPAM\"]}\n",
    "std_dict = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c492a171",
   "metadata": {},
   "source": [
    "## Evaluate ESPAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024b48ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 2 if dataset_name != \"ba2motifs\" else 5\n",
    "mask_func = lambda smiles, values, k: top_k_percent_nodes(values, k)   \n",
    "#for l in range(2, 6):\n",
    "for method in [\"ESPAM\"]:\n",
    "    hfidelity_dict[method] = 0\n",
    "    hfid_val[method] = []\n",
    "    cnt = 0\n",
    "\n",
    "with open(f\"{dataset_name}_ESPAM_results_{l=}.pkl\", \"rb\") as f:\n",
    "    ESPAMS = pickle.load(f)\n",
    "for i, data in tqdm(enumerate(dataset)):\n",
    "    x, edge_index = data.x, data.edge_index\n",
    "    #seq = bert_function(seq_id).reshape(1, -1)\n",
    "    target_class = model(x, edge_index)[0].argmax().item()\n",
    "    espams = ESPAMS[i]\n",
    "    add_to_metrics_dict(data, espams, mask_func, model, target_class, \"ESPAM\")\n",
    "\n",
    "for method in [\"ESPAM\"]:\n",
    "    devide_metric_values(method, cnt)\n",
    "    std_dict[method] = np.std(list(map(lambda x: x.detach().cpu().numpy(), hfid_val[method])))\n",
    "    print(f\"{l=} {hfidelity_dict[method]} ± {std_dict[method]}\")\n",
    "    #print(f\"protein: {protein}\\t espam hfid: {hfidelity_dict[(protein, 'ESPAM')]} ± {std_dict[(protein, 'ESPAM')]}\\t gstar hfid: {hfidelity_dict[(protein, 'gstarx')]} ± {std_dict[(protein, 'gstarx')]}\\t shap hfid: {hfidelity_dict[(protein, 'shap')]} ± {std_dict[(protein, 'shap')]}\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79116d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn_explainer_mask(data):\n",
    "    edge_mask = data.edge_mask\n",
    "    edge_mask = edge_mask > 0.5\n",
    "    return edge_mask \n",
    "\n",
    "def edge_soft_mask(values, number_of_edges):\n",
    "    values = torch.tensor(values)\n",
    "    number_of_nodes = values.shape[0]\n",
    "    _, indices = torch.sort(values, descending=True)\n",
    "    selected_indices = indices[:number_of_edges]\n",
    "    mask = torch.zeros(values.shape[0])\n",
    "    mask[selected_indices] = 1\n",
    "    return mask.to(bool)\n",
    "\n",
    "def subgraph_mask(number_of_nodes, indices):\n",
    "    mask = torch.zeros(number_of_nodes)\n",
    "    mask[indices] = 1\n",
    "    mask = mask.bool()\n",
    "    return mask \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a382e0d",
   "metadata": {},
   "source": [
    "### Run Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfid_dict = {}\n",
    "min_sparsity = 0.5\n",
    "hfid_val = {}\n",
    "hfid_dict = {}\n",
    "mask_func_edge = lambda x, y: creat_mask_mol_data(x, y, is_edge=True)\n",
    "mask_func_node = lambda x, y: creat_mask_mol_data(x, y, is_edge=False)\n",
    "\n",
    "explanation_data = explain_dict#exp1\n",
    "for index, explainers in tqdm(explanation_data.items()):\n",
    "    number_of_nodes = features[index].shape[0]\n",
    "    target_class = model(features[index], graphs[index])[0].argmax().item()\n",
    "    data = dataset[index].clone()\n",
    "    for explainer, explanations in explainers.items():\n",
    "        if explainer not in hfid_dict:\n",
    "            hfid_dict[explainer] = 0\n",
    "            hfid_val[explainer] = []\n",
    "        if explainer == \"GNNExplainer\":\n",
    "            mask = gnn_explainer_mask(explanations)\n",
    "            hfid = hfidelity(data, mask, model, target_class, mask_func_edge)\n",
    "            hfid_val[explainer].append(hfid)\n",
    "            hfid_dict[explainer] += hfid\n",
    "        elif explainer == \"PGExplainer\":\n",
    "            values = explanations[1]\n",
    "            max_h_fid = 0 \n",
    "            for i in range(values.shape[0]):\n",
    "                mask = edge_soft_mask(values, i)\n",
    "                hfid = hfidelity(data, mask, model, target_class, mask_func_edge)\n",
    "                max_h_fid = max(hfid, max_h_fid)\n",
    "                sparsity = 1 - mask_func_edge(data, mask).node_mask_size/data.x.shape[0]\n",
    "                if sparsity < min_sparsity:\n",
    "                    break\n",
    "            hfid_val[explainer].append(max_h_fid)  \n",
    "            hfid_dict[explainer] += max_h_fid\n",
    "                    \n",
    "        elif explainer == \"PGM\":\n",
    "            mask = explanations[1].bool()\n",
    "            hfid = hfidelity(data, mask, model, target_class, mask_func_edge)\n",
    "            hfid_val[explainer].append(hfid)\n",
    "            hfid_dict[explainer] += hfid\n",
    "        elif explainer == \"gstar\":\n",
    "            explanations = torch.tensor(explanations)\n",
    "            max_h_fid = 0\n",
    "            for i in range(number_of_nodes):\n",
    "                mask = top_k_percent_nodes(explanations, i)\n",
    "                hfid = hfidelity(data, mask, model, target_class, mask_func_node)\n",
    "                max_h_fid = max(hfid, max_h_fid)\n",
    "                sparsity =  1 - i/number_of_nodes\n",
    "                if sparsity < min_sparsity:\n",
    "                    break\n",
    "            hfid_val[explainer].append(max_h_fid)\n",
    "            hfid_dict[explainer] += max_h_fid\n",
    "        elif explainer == \"SVX\":\n",
    "            values = explanations[0][1][:number_of_nodes]\n",
    "            max_h_fid = 0\n",
    "            if values.shape[0] < number_of_nodes:\n",
    "                values = torch.cat([values, torch.zeros(number_of_nodes - values.shape[0])])\n",
    "            for i in range(number_of_nodes):\n",
    "                mask = top_k_percent_nodes(values, i)\n",
    "                hfid = hfidelity(data, mask, model, target_class, mask_func_node)\n",
    "                max_h_fid = max(hfid, max_h_fid)\n",
    "                sparsity =  1 - i/number_of_nodes\n",
    "                if sparsity < min_sparsity:\n",
    "                    break\n",
    "            hfid_val[explainer].append(max_h_fid)\n",
    "            hfid_dict[explainer] += max_h_fid\n",
    "\n",
    "        elif explainer == \"subgraph\":\n",
    "            mask = subgraph_mask(number_of_nodes, explanations)\n",
    "            hfid = hfidelity(data, mask, model, target_class, mask_func_node)\n",
    "            hfid_val[explainer].append(hfid)\n",
    "            hfid_dict[explainer] += hfid\n",
    "            \n",
    "        elif explainer == \"GradCAM\":\n",
    "            values = explanations.node_imp\n",
    "            max_h_fid = 0\n",
    "            for i in range(number_of_nodes):\n",
    "                mask = top_k_percent_nodes(values, i)\n",
    "                hfid = hfidelity(data, mask, model, target_class, mask_func_node)\n",
    "                max_h_fid = max(hfid, max_h_fid)\n",
    "                sparsity =  1 - i/number_of_nodes\n",
    "                if sparsity < min_sparsity:\n",
    "                    break\n",
    "            hfid_val[explainer].append(max_h_fid)\n",
    "            hfid_dict[explainer] += max_h_fid\n",
    "        else: \n",
    "            pass\n",
    "for explainer in hfid_dict.keys():\n",
    "    res_dict[(explainer, run)] = hfid_dict[explainer]/len(explanation_data)\n",
    "    with open(f\"{dataset_name}_res.pkl\", \"wb\") as file:\n",
    "        pickle.dump(res_dict, file)\n",
    "# Clear variables and free up memory\n",
    "#del explain_dict, hfid_dict, hfid_val, explanation_data, data, mask, values, max_h_fid, sparsity, target_class\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f9f92",
   "metadata": {},
   "source": [
    "### T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "936513fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.5460, grad_fn=<DivBackward0>), tensor(0.5368, grad_fn=<DivBackward0>), tensor(0.5421, grad_fn=<DivBackward0>), tensor(0.5225, grad_fn=<DivBackward0>), tensor(0.5493, grad_fn=<DivBackward0>), tensor(0.5872, grad_fn=<DivBackward0>), tensor(0.5643, grad_fn=<DivBackward0>), tensor(0.5402, grad_fn=<DivBackward0>), tensor(0.5226, grad_fn=<DivBackward0>), tensor(0.5477, grad_fn=<DivBackward0>), tensor(0.5077, grad_fn=<DivBackward0>), tensor(0.6277, grad_fn=<DivBackward0>), tensor(0.5406, grad_fn=<DivBackward0>), tensor(0.5415, grad_fn=<DivBackward0>), tensor(0.5437, grad_fn=<DivBackward0>), tensor(0.5059, grad_fn=<DivBackward0>), tensor(0.5139, grad_fn=<DivBackward0>), tensor(0.5354, grad_fn=<DivBackward0>), tensor(0.5558, grad_fn=<DivBackward0>), tensor(0.5869, grad_fn=<DivBackward0>), tensor(0.5175, grad_fn=<DivBackward0>), tensor(0.5951, grad_fn=<DivBackward0>), tensor(0.5363, grad_fn=<DivBackward0>), tensor(0.5285, grad_fn=<DivBackward0>), tensor(0.6269, grad_fn=<DivBackward0>), tensor(0.5568, grad_fn=<DivBackward0>), tensor(0.6191, grad_fn=<DivBackward0>), tensor(0.5515, grad_fn=<DivBackward0>), tensor(0.5296, grad_fn=<DivBackward0>), tensor(0.5282, grad_fn=<DivBackward0>), tensor(0.5001, grad_fn=<DivBackward0>), tensor(0.5359, grad_fn=<DivBackward0>), tensor(0.5488, grad_fn=<DivBackward0>), tensor(0.5481, grad_fn=<DivBackward0>), tensor(0.5817, grad_fn=<DivBackward0>), tensor(0.5146, grad_fn=<DivBackward0>), tensor(0.5306, grad_fn=<DivBackward0>), tensor(0.5604, grad_fn=<DivBackward0>), tensor(0.5263, grad_fn=<DivBackward0>), tensor(0.5770, grad_fn=<DivBackward0>), tensor(0.5367, grad_fn=<DivBackward0>), tensor(0.5502, grad_fn=<DivBackward0>), tensor(0.5036, grad_fn=<DivBackward0>), tensor(0.5916, grad_fn=<DivBackward0>), tensor(0.5786, grad_fn=<DivBackward0>), tensor(0.5231, grad_fn=<DivBackward0>), tensor(0.6088, grad_fn=<DivBackward0>), tensor(0.6269, grad_fn=<DivBackward0>), tensor(0.6113, grad_fn=<DivBackward0>), tensor(0.5572, grad_fn=<DivBackward0>), tensor(0.5011, grad_fn=<DivBackward0>), tensor(0.5295, grad_fn=<DivBackward0>), tensor(0.5277, grad_fn=<DivBackward0>), tensor(0.6149, grad_fn=<DivBackward0>), tensor(0.5044, grad_fn=<DivBackward0>), tensor(0.5555, grad_fn=<DivBackward0>), tensor(0.5979, grad_fn=<DivBackward0>), tensor(0.6331, grad_fn=<DivBackward0>), tensor(0.6102, grad_fn=<DivBackward0>), tensor(0.6013, grad_fn=<DivBackward0>), tensor(0.5370, grad_fn=<DivBackward0>), tensor(0.5604, grad_fn=<DivBackward0>), tensor(0.5437, grad_fn=<DivBackward0>), tensor(0.6189, grad_fn=<DivBackward0>), tensor(0.5842, grad_fn=<DivBackward0>), tensor(0.5813, grad_fn=<DivBackward0>), tensor(0.5269, grad_fn=<DivBackward0>), tensor(0.5432, grad_fn=<DivBackward0>), tensor(0.5449, grad_fn=<DivBackward0>), tensor(0.4352, grad_fn=<DivBackward0>), tensor(0.5567, grad_fn=<DivBackward0>), tensor(0.4965, grad_fn=<DivBackward0>), tensor(0.5597, grad_fn=<DivBackward0>), tensor(0.5319, grad_fn=<DivBackward0>), tensor(0.5151, grad_fn=<DivBackward0>), tensor(0.5092, grad_fn=<DivBackward0>), tensor(0.5457, grad_fn=<DivBackward0>), tensor(0.5276, grad_fn=<DivBackward0>), tensor(0.6110, grad_fn=<DivBackward0>), tensor(0.5203, grad_fn=<DivBackward0>), tensor(0.6198, grad_fn=<DivBackward0>), tensor(0.5677, grad_fn=<DivBackward0>), tensor(0.5786, grad_fn=<DivBackward0>), tensor(0.5538, grad_fn=<DivBackward0>), tensor(0.5348, grad_fn=<DivBackward0>), tensor(0.6008, grad_fn=<DivBackward0>), tensor(0.5963, grad_fn=<DivBackward0>), tensor(0.5379, grad_fn=<DivBackward0>), tensor(0.4966, grad_fn=<DivBackward0>), tensor(0.5032, grad_fn=<DivBackward0>), tensor(0.5518, grad_fn=<DivBackward0>), tensor(0.6338, grad_fn=<DivBackward0>), tensor(0.5397, grad_fn=<DivBackward0>), tensor(0.5357, grad_fn=<DivBackward0>), tensor(0.5043, grad_fn=<DivBackward0>), tensor(0.5822, grad_fn=<DivBackward0>), tensor(0.5255, grad_fn=<DivBackward0>), tensor(0.5359, grad_fn=<DivBackward0>), tensor(0.5839, grad_fn=<DivBackward0>), tensor(0.6190, grad_fn=<DivBackward0>), tensor(0.5891, grad_fn=<DivBackward0>), tensor(0.5348, grad_fn=<DivBackward0>), tensor(0.5784, grad_fn=<DivBackward0>), tensor(0.5101, grad_fn=<DivBackward0>), tensor(0.5271, grad_fn=<DivBackward0>), tensor(0.5362, grad_fn=<DivBackward0>), tensor(0.5690, grad_fn=<DivBackward0>), tensor(0.5794, grad_fn=<DivBackward0>), tensor(0.6384, grad_fn=<DivBackward0>), tensor(0.6376, grad_fn=<DivBackward0>), tensor(0.5616, grad_fn=<DivBackward0>), tensor(0.5400, grad_fn=<DivBackward0>), tensor(0.6126, grad_fn=<DivBackward0>), tensor(0.5410, grad_fn=<DivBackward0>), tensor(0.5578, grad_fn=<DivBackward0>), tensor(0.5523, grad_fn=<DivBackward0>), tensor(0.6096, grad_fn=<DivBackward0>), tensor(0.6171, grad_fn=<DivBackward0>), tensor(0.5535, grad_fn=<DivBackward0>), tensor(0.6212, grad_fn=<DivBackward0>), tensor(0.5017, grad_fn=<DivBackward0>), tensor(0.5315, grad_fn=<DivBackward0>), tensor(0.5942, grad_fn=<DivBackward0>), tensor(0.5317, grad_fn=<DivBackward0>), tensor(0.5361, grad_fn=<DivBackward0>), tensor(0.5280, grad_fn=<DivBackward0>), tensor(0.5366, grad_fn=<DivBackward0>), tensor(0.5427, grad_fn=<DivBackward0>), tensor(0.6372, grad_fn=<DivBackward0>), tensor(0.5091, grad_fn=<DivBackward0>), tensor(0.5052, grad_fn=<DivBackward0>), tensor(0.5765, grad_fn=<DivBackward0>), tensor(0.5530, grad_fn=<DivBackward0>), tensor(0.5658, grad_fn=<DivBackward0>), tensor(0.5421, grad_fn=<DivBackward0>), tensor(0.5800, grad_fn=<DivBackward0>), tensor(0.5428, grad_fn=<DivBackward0>), tensor(0.5554, grad_fn=<DivBackward0>), tensor(0.5153, grad_fn=<DivBackward0>), tensor(0.5952, grad_fn=<DivBackward0>), tensor(0.5433, grad_fn=<DivBackward0>), tensor(0.6293, grad_fn=<DivBackward0>), tensor(0.5480, grad_fn=<DivBackward0>), tensor(0.5626, grad_fn=<DivBackward0>), tensor(0.6211, grad_fn=<DivBackward0>), tensor(0.6154, grad_fn=<DivBackward0>), tensor(0.5408, grad_fn=<DivBackward0>), tensor(0.5394, grad_fn=<DivBackward0>), tensor(0.6258, grad_fn=<DivBackward0>), tensor(0.5040, grad_fn=<DivBackward0>), tensor(0.6024, grad_fn=<DivBackward0>), tensor(0.5335, grad_fn=<DivBackward0>), tensor(0.5289, grad_fn=<DivBackward0>), tensor(0.5264, grad_fn=<DivBackward0>), tensor(0.5262, grad_fn=<DivBackward0>), tensor(0.6332, grad_fn=<DivBackward0>), tensor(0.6359, grad_fn=<DivBackward0>), tensor(0.5348, grad_fn=<DivBackward0>), tensor(0.5305, grad_fn=<DivBackward0>), tensor(0.5051, grad_fn=<DivBackward0>), tensor(0.5341, grad_fn=<DivBackward0>), tensor(0.6054, grad_fn=<DivBackward0>), tensor(0.5433, grad_fn=<DivBackward0>), tensor(0.6199, grad_fn=<DivBackward0>), tensor(0.4849, grad_fn=<DivBackward0>), tensor(0.5564, grad_fn=<DivBackward0>), tensor(0.5910, grad_fn=<DivBackward0>), tensor(0.5440, grad_fn=<DivBackward0>), tensor(0.5068, grad_fn=<DivBackward0>), tensor(0.5931, grad_fn=<DivBackward0>), tensor(0.5299, grad_fn=<DivBackward0>), tensor(0.5811, grad_fn=<DivBackward0>), tensor(0.6329, grad_fn=<DivBackward0>), tensor(0.5299, grad_fn=<DivBackward0>), tensor(0.5320, grad_fn=<DivBackward0>), tensor(0.6293, grad_fn=<DivBackward0>), tensor(0.5306, grad_fn=<DivBackward0>), tensor(0.5817, grad_fn=<DivBackward0>), tensor(0.6284, grad_fn=<DivBackward0>), tensor(0.5297, grad_fn=<DivBackward0>), tensor(0.5460, grad_fn=<DivBackward0>), tensor(0.5633, grad_fn=<DivBackward0>), tensor(0.5253, grad_fn=<DivBackward0>), tensor(0.6023, grad_fn=<DivBackward0>), tensor(0.6263, grad_fn=<DivBackward0>), tensor(0.5852, grad_fn=<DivBackward0>), tensor(0.5505, grad_fn=<DivBackward0>), tensor(0.6218, grad_fn=<DivBackward0>), tensor(0.5551, grad_fn=<DivBackward0>), tensor(0.5483, grad_fn=<DivBackward0>), tensor(0.5706, grad_fn=<DivBackward0>), tensor(0.5475, grad_fn=<DivBackward0>), tensor(0.5359, grad_fn=<DivBackward0>), tensor(0.5167, grad_fn=<DivBackward0>), tensor(0.5255, grad_fn=<DivBackward0>), tensor(0.5444, grad_fn=<DivBackward0>), tensor(0.6348, grad_fn=<DivBackward0>), tensor(0.5284, grad_fn=<DivBackward0>), tensor(0.5335, grad_fn=<DivBackward0>), tensor(0.5954, grad_fn=<DivBackward0>), tensor(0.5437, grad_fn=<DivBackward0>), tensor(0.5100, grad_fn=<DivBackward0>), tensor(0.5769, grad_fn=<DivBackward0>), tensor(0.5782, grad_fn=<DivBackward0>), tensor(0.6289, grad_fn=<DivBackward0>), tensor(0.6362, grad_fn=<DivBackward0>), tensor(0.5734, grad_fn=<DivBackward0>), tensor(0.5613, grad_fn=<DivBackward0>), tensor(0.5366, grad_fn=<DivBackward0>), tensor(0.5272, grad_fn=<DivBackward0>), tensor(0.5316, grad_fn=<DivBackward0>), tensor(0.5639, grad_fn=<DivBackward0>), tensor(0.5377, grad_fn=<DivBackward0>), tensor(0.5034, grad_fn=<DivBackward0>), tensor(0.5011, grad_fn=<DivBackward0>), tensor(0.5078, grad_fn=<DivBackward0>), tensor(0.6376, grad_fn=<DivBackward0>), tensor(0.5855, grad_fn=<DivBackward0>), tensor(0.5531, grad_fn=<DivBackward0>), tensor(0.5364, grad_fn=<DivBackward0>), tensor(0.5780, grad_fn=<DivBackward0>), tensor(0.5962, grad_fn=<DivBackward0>), tensor(0.5708, grad_fn=<DivBackward0>), tensor(0.5136, grad_fn=<DivBackward0>), tensor(0.5234, grad_fn=<DivBackward0>), tensor(0.5762, grad_fn=<DivBackward0>), tensor(0.5871, grad_fn=<DivBackward0>), tensor(0.5068, grad_fn=<DivBackward0>), tensor(0.5341, grad_fn=<DivBackward0>), tensor(0.6223, grad_fn=<DivBackward0>), tensor(0.5754, grad_fn=<DivBackward0>), tensor(0.5265, grad_fn=<DivBackward0>), tensor(0.5517, grad_fn=<DivBackward0>), tensor(0.5353, grad_fn=<DivBackward0>), tensor(0.6104, grad_fn=<DivBackward0>), tensor(0.5911, grad_fn=<DivBackward0>), tensor(0.5297, grad_fn=<DivBackward0>), tensor(0.5738, grad_fn=<DivBackward0>), tensor(0.5406, grad_fn=<DivBackward0>), tensor(0.5276, grad_fn=<DivBackward0>), tensor(0.5543, grad_fn=<DivBackward0>), tensor(0.5647, grad_fn=<DivBackward0>), tensor(0.6183, grad_fn=<DivBackward0>), tensor(0.6234, grad_fn=<DivBackward0>), tensor(0.5119, grad_fn=<DivBackward0>), tensor(0.5160, grad_fn=<DivBackward0>), tensor(0.5382, grad_fn=<DivBackward0>), tensor(0.5044, grad_fn=<DivBackward0>), tensor(0.5151, grad_fn=<DivBackward0>), tensor(0.5396, grad_fn=<DivBackward0>), tensor(0.5209, grad_fn=<DivBackward0>), tensor(0.5706, grad_fn=<DivBackward0>), tensor(0.5394, grad_fn=<DivBackward0>), tensor(0.5333, grad_fn=<DivBackward0>), tensor(0.5651, grad_fn=<DivBackward0>), tensor(0.5259, grad_fn=<DivBackward0>), tensor(0.5317, grad_fn=<DivBackward0>), tensor(0.5125, grad_fn=<DivBackward0>), tensor(0.5029, grad_fn=<DivBackward0>), tensor(0.5340, grad_fn=<DivBackward0>), tensor(0.6021, grad_fn=<DivBackward0>), tensor(0.5767, grad_fn=<DivBackward0>), tensor(0.5318, grad_fn=<DivBackward0>), tensor(0.5954, grad_fn=<DivBackward0>), tensor(0.5686, grad_fn=<DivBackward0>), tensor(0.5946, grad_fn=<DivBackward0>), tensor(0.5294, grad_fn=<DivBackward0>), tensor(0.5284, grad_fn=<DivBackward0>), tensor(0.5208, grad_fn=<DivBackward0>), tensor(0.6023, grad_fn=<DivBackward0>), tensor(0.5353, grad_fn=<DivBackward0>), tensor(0.6168, grad_fn=<DivBackward0>), tensor(0.6488, grad_fn=<DivBackward0>), tensor(0.5522, grad_fn=<DivBackward0>), tensor(0.5270, grad_fn=<DivBackward0>), tensor(0.5363, grad_fn=<DivBackward0>), tensor(0.5432, grad_fn=<DivBackward0>), tensor(0.6166, grad_fn=<DivBackward0>), tensor(0.5448, grad_fn=<DivBackward0>), tensor(0.5491, grad_fn=<DivBackward0>), tensor(0.5375, grad_fn=<DivBackward0>), tensor(0.5404, grad_fn=<DivBackward0>), tensor(0.6138, grad_fn=<DivBackward0>), tensor(0.5324, grad_fn=<DivBackward0>), tensor(0.5827, grad_fn=<DivBackward0>), tensor(0.5834, grad_fn=<DivBackward0>), tensor(0.6190, grad_fn=<DivBackward0>), tensor(0.5197, grad_fn=<DivBackward0>), tensor(0.5175, grad_fn=<DivBackward0>), tensor(0.6288, grad_fn=<DivBackward0>), tensor(0.5803, grad_fn=<DivBackward0>), tensor(0.5720, grad_fn=<DivBackward0>), tensor(0.5359, grad_fn=<DivBackward0>), tensor(0.5270, grad_fn=<DivBackward0>), tensor(0.6445, grad_fn=<DivBackward0>), tensor(0.5551, grad_fn=<DivBackward0>), tensor(0.5337, grad_fn=<DivBackward0>), tensor(0.6053, grad_fn=<DivBackward0>), tensor(0.5722, grad_fn=<DivBackward0>), tensor(0.5174, grad_fn=<DivBackward0>), tensor(0.5733, grad_fn=<DivBackward0>), tensor(0.5517, grad_fn=<DivBackward0>), tensor(0.5426, grad_fn=<DivBackward0>), tensor(0.5353, grad_fn=<DivBackward0>), tensor(0.5707, grad_fn=<DivBackward0>), tensor(0.5125, grad_fn=<DivBackward0>), tensor(0.5027, grad_fn=<DivBackward0>), tensor(0.5741, grad_fn=<DivBackward0>), tensor(0.5174, grad_fn=<DivBackward0>), tensor(0.5272, grad_fn=<DivBackward0>), tensor(0.5758, grad_fn=<DivBackward0>), tensor(0.6093, grad_fn=<DivBackward0>), tensor(0.5369, grad_fn=<DivBackward0>), tensor(0.6390, grad_fn=<DivBackward0>), tensor(0.6124, grad_fn=<DivBackward0>), tensor(0.5798, grad_fn=<DivBackward0>), tensor(0.5871, grad_fn=<DivBackward0>), tensor(0.6078, grad_fn=<DivBackward0>), tensor(0.5340, grad_fn=<DivBackward0>), tensor(0.5377, grad_fn=<DivBackward0>), tensor(0.6028, grad_fn=<DivBackward0>), tensor(0.5933, grad_fn=<DivBackward0>), tensor(0.5210, grad_fn=<DivBackward0>), tensor(0.5399, grad_fn=<DivBackward0>), tensor(0.5350, grad_fn=<DivBackward0>), tensor(0.5240, grad_fn=<DivBackward0>), tensor(0.5524, grad_fn=<DivBackward0>), tensor(0.5267, grad_fn=<DivBackward0>), tensor(0.5551, grad_fn=<DivBackward0>), tensor(0.5388, grad_fn=<DivBackward0>), tensor(0.5219, grad_fn=<DivBackward0>), tensor(0.5573, grad_fn=<DivBackward0>), tensor(0.5491, grad_fn=<DivBackward0>), tensor(0.5983, grad_fn=<DivBackward0>), tensor(0.5342, grad_fn=<DivBackward0>), tensor(0.6355, grad_fn=<DivBackward0>), tensor(0.5318, grad_fn=<DivBackward0>), tensor(0.5915, grad_fn=<DivBackward0>), tensor(0.5157, grad_fn=<DivBackward0>), tensor(0.6213, grad_fn=<DivBackward0>), tensor(0.5524, grad_fn=<DivBackward0>), tensor(0.5587, grad_fn=<DivBackward0>), tensor(0.6202, grad_fn=<DivBackward0>), tensor(0.5365, grad_fn=<DivBackward0>), tensor(0.5548, grad_fn=<DivBackward0>), tensor(0.5654, grad_fn=<DivBackward0>), tensor(0.5588, grad_fn=<DivBackward0>), tensor(0.5144, grad_fn=<DivBackward0>), tensor(0.6154, grad_fn=<DivBackward0>), tensor(0.5065, grad_fn=<DivBackward0>), tensor(0.5216, grad_fn=<DivBackward0>), tensor(0.5546, grad_fn=<DivBackward0>), tensor(0.5409, grad_fn=<DivBackward0>), tensor(0.6020, grad_fn=<DivBackward0>), tensor(0.5259, grad_fn=<DivBackward0>), tensor(0.5555, grad_fn=<DivBackward0>), tensor(0.6177, grad_fn=<DivBackward0>), tensor(0.6065, grad_fn=<DivBackward0>), tensor(0.5345, grad_fn=<DivBackward0>), tensor(0.5306, grad_fn=<DivBackward0>), tensor(0.5192, grad_fn=<DivBackward0>), tensor(0.5668, grad_fn=<DivBackward0>), tensor(0.5801, grad_fn=<DivBackward0>), tensor(0.5380, grad_fn=<DivBackward0>), tensor(0.5477, grad_fn=<DivBackward0>), tensor(0.5177, grad_fn=<DivBackward0>), tensor(0.6432, grad_fn=<DivBackward0>), tensor(0.5440, grad_fn=<DivBackward0>), tensor(0.5853, grad_fn=<DivBackward0>), tensor(0.6075, grad_fn=<DivBackward0>), tensor(0.6103, grad_fn=<DivBackward0>), tensor(0.5264, grad_fn=<DivBackward0>), tensor(0.5349, grad_fn=<DivBackward0>), tensor(0.5379, grad_fn=<DivBackward0>), tensor(0.5307, grad_fn=<DivBackward0>), tensor(0.5493, grad_fn=<DivBackward0>), tensor(0.5392, grad_fn=<DivBackward0>), tensor(0.6150, grad_fn=<DivBackward0>), tensor(0.5370, grad_fn=<DivBackward0>), tensor(0.5250, grad_fn=<DivBackward0>), tensor(0.5434, grad_fn=<DivBackward0>), tensor(0.5354, grad_fn=<DivBackward0>), tensor(0.6242, grad_fn=<DivBackward0>), tensor(0.6199, grad_fn=<DivBackward0>), tensor(0.5727, grad_fn=<DivBackward0>), tensor(0.5442, grad_fn=<DivBackward0>), tensor(0.5198, grad_fn=<DivBackward0>), tensor(0.5195, grad_fn=<DivBackward0>), tensor(0.5416, grad_fn=<DivBackward0>), tensor(0.5446, grad_fn=<DivBackward0>), tensor(0.6079, grad_fn=<DivBackward0>), tensor(0.5154, grad_fn=<DivBackward0>), tensor(0.5740, grad_fn=<DivBackward0>), tensor(0.5011, grad_fn=<DivBackward0>), tensor(0.5307, grad_fn=<DivBackward0>), tensor(0.5919, grad_fn=<DivBackward0>), tensor(0.4873, grad_fn=<DivBackward0>), tensor(0.4998, grad_fn=<DivBackward0>), tensor(0.5896, grad_fn=<DivBackward0>), tensor(0.6159, grad_fn=<DivBackward0>), tensor(0.5416, grad_fn=<DivBackward0>), tensor(0.6264, grad_fn=<DivBackward0>), tensor(0.5731, grad_fn=<DivBackward0>), tensor(0.6079, grad_fn=<DivBackward0>), tensor(0.5714, grad_fn=<DivBackward0>), tensor(0.5111, grad_fn=<DivBackward0>), tensor(0.5094, grad_fn=<DivBackward0>), tensor(0.5146, grad_fn=<DivBackward0>), tensor(0.5808, grad_fn=<DivBackward0>), tensor(0.5434, grad_fn=<DivBackward0>), tensor(0.5041, grad_fn=<DivBackward0>), tensor(0.4998, grad_fn=<DivBackward0>), tensor(0.5300, grad_fn=<DivBackward0>), tensor(0.5919, grad_fn=<DivBackward0>), tensor(0.5383, grad_fn=<DivBackward0>), tensor(0.5113, grad_fn=<DivBackward0>), tensor(0.5280, grad_fn=<DivBackward0>), tensor(0.5198, grad_fn=<DivBackward0>), tensor(0.5045, grad_fn=<DivBackward0>), tensor(0.4995, grad_fn=<DivBackward0>), tensor(0.6064, grad_fn=<DivBackward0>), tensor(0.6351, grad_fn=<DivBackward0>), tensor(0.6470, grad_fn=<DivBackward0>), tensor(0.5332, grad_fn=<DivBackward0>), tensor(0.5647, grad_fn=<DivBackward0>), tensor(0.5331, grad_fn=<DivBackward0>), tensor(0.5958, grad_fn=<DivBackward0>), tensor(0.5507, grad_fn=<DivBackward0>), tensor(0.5471, grad_fn=<DivBackward0>), tensor(0.6145, grad_fn=<DivBackward0>), tensor(0.5085, grad_fn=<DivBackward0>), tensor(0.5430, grad_fn=<DivBackward0>), tensor(0.5617, grad_fn=<DivBackward0>), tensor(0.5041, grad_fn=<DivBackward0>), tensor(0.6296, grad_fn=<DivBackward0>), tensor(0.5323, grad_fn=<DivBackward0>), tensor(0.5443, grad_fn=<DivBackward0>), tensor(0.5394, grad_fn=<DivBackward0>), tensor(0.5566, grad_fn=<DivBackward0>), tensor(0.5459, grad_fn=<DivBackward0>), tensor(0.4990, grad_fn=<DivBackward0>), tensor(0.6285, grad_fn=<DivBackward0>), tensor(0.4999, grad_fn=<DivBackward0>), tensor(0.5430, grad_fn=<DivBackward0>), tensor(0.5367, grad_fn=<DivBackward0>), tensor(0.5806, grad_fn=<DivBackward0>), tensor(0.5379, grad_fn=<DivBackward0>), tensor(0.5503, grad_fn=<DivBackward0>), tensor(0.6021, grad_fn=<DivBackward0>), tensor(0.4802, grad_fn=<DivBackward0>), tensor(0.6072, grad_fn=<DivBackward0>), tensor(0.5787, grad_fn=<DivBackward0>), tensor(0.6118, grad_fn=<DivBackward0>), tensor(0.5260, grad_fn=<DivBackward0>), tensor(0.5055, grad_fn=<DivBackward0>), tensor(0.5498, grad_fn=<DivBackward0>), tensor(0.5375, grad_fn=<DivBackward0>), tensor(0.5693, grad_fn=<DivBackward0>), tensor(0.5722, grad_fn=<DivBackward0>), tensor(0.6399, grad_fn=<DivBackward0>), tensor(0.5413, grad_fn=<DivBackward0>), tensor(0.5227, grad_fn=<DivBackward0>), tensor(0.5423, grad_fn=<DivBackward0>), tensor(0.6409, grad_fn=<DivBackward0>), tensor(0.5612, grad_fn=<DivBackward0>), tensor(0.5334, grad_fn=<DivBackward0>), tensor(0.5318, grad_fn=<DivBackward0>), tensor(0.5221, grad_fn=<DivBackward0>), tensor(0.5564, grad_fn=<DivBackward0>), tensor(0.6071, grad_fn=<DivBackward0>), tensor(0.5784, grad_fn=<DivBackward0>), tensor(0.6200, grad_fn=<DivBackward0>), tensor(0.5459, grad_fn=<DivBackward0>), tensor(0.6385, grad_fn=<DivBackward0>), tensor(0.5966, grad_fn=<DivBackward0>), tensor(0.5994, grad_fn=<DivBackward0>), tensor(0.6361, grad_fn=<DivBackward0>), tensor(0.5849, grad_fn=<DivBackward0>), tensor(0.5867, grad_fn=<DivBackward0>), tensor(0.4953, grad_fn=<DivBackward0>), tensor(0.5462, grad_fn=<DivBackward0>), tensor(0.6100, grad_fn=<DivBackward0>), tensor(0.5402, grad_fn=<DivBackward0>), tensor(0.6402, grad_fn=<DivBackward0>), tensor(0.5689, grad_fn=<DivBackward0>), tensor(0.5526, grad_fn=<DivBackward0>), tensor(0.5777, grad_fn=<DivBackward0>), tensor(0.6192, grad_fn=<DivBackward0>), tensor(0.5549, grad_fn=<DivBackward0>), tensor(0.5247, grad_fn=<DivBackward0>), tensor(0.5168, grad_fn=<DivBackward0>), tensor(0.5271, grad_fn=<DivBackward0>), tensor(0.5960, grad_fn=<DivBackward0>), tensor(0.5644, grad_fn=<DivBackward0>), tensor(0.5617, grad_fn=<DivBackward0>), tensor(0.5809, grad_fn=<DivBackward0>), tensor(0.5681, grad_fn=<DivBackward0>), tensor(0.5133, grad_fn=<DivBackward0>), tensor(0.5437, grad_fn=<DivBackward0>), tensor(0.5322, grad_fn=<DivBackward0>), tensor(0.6009, grad_fn=<DivBackward0>), tensor(0.5464, grad_fn=<DivBackward0>), tensor(0.5735, grad_fn=<DivBackward0>), tensor(0.5350, grad_fn=<DivBackward0>), tensor(0.5561, grad_fn=<DivBackward0>), tensor(0.5102, grad_fn=<DivBackward0>), tensor(0.6229, grad_fn=<DivBackward0>), tensor(0.5758, grad_fn=<DivBackward0>), tensor(0.6327, grad_fn=<DivBackward0>), tensor(0.6317, grad_fn=<DivBackward0>), tensor(0.5507, grad_fn=<DivBackward0>), tensor(0.5062, grad_fn=<DivBackward0>), tensor(0.5344, grad_fn=<DivBackward0>), tensor(0.5090, grad_fn=<DivBackward0>), tensor(0.5222, grad_fn=<DivBackward0>), tensor(0.5109, grad_fn=<DivBackward0>), tensor(0.6352, grad_fn=<DivBackward0>), tensor(0.6042, grad_fn=<DivBackward0>), tensor(0.5314, grad_fn=<DivBackward0>), tensor(0.6291, grad_fn=<DivBackward0>), tensor(0.4925, grad_fn=<DivBackward0>), tensor(0.5179, grad_fn=<DivBackward0>), tensor(0.5050, grad_fn=<DivBackward0>), tensor(0.5534, grad_fn=<DivBackward0>), tensor(0.5761, grad_fn=<DivBackward0>), tensor(0.5398, grad_fn=<DivBackward0>), tensor(0.5222, grad_fn=<DivBackward0>), tensor(0.5615, grad_fn=<DivBackward0>), tensor(0.6072, grad_fn=<DivBackward0>), tensor(0.5116, grad_fn=<DivBackward0>), tensor(0.5557, grad_fn=<DivBackward0>), tensor(0.5333, grad_fn=<DivBackward0>), tensor(0.5390, grad_fn=<DivBackward0>), tensor(0.5349, grad_fn=<DivBackward0>), tensor(0.4989, grad_fn=<DivBackward0>), tensor(0.5344, grad_fn=<DivBackward0>), tensor(0.5797, grad_fn=<DivBackward0>), tensor(0.4998, grad_fn=<DivBackward0>), tensor(0.5864, grad_fn=<DivBackward0>), tensor(0.6070, grad_fn=<DivBackward0>), tensor(0.5359, grad_fn=<DivBackward0>), tensor(0.5672, grad_fn=<DivBackward0>), tensor(0.5426, grad_fn=<DivBackward0>), tensor(0.5678, grad_fn=<DivBackward0>), tensor(0.5049, grad_fn=<DivBackward0>), tensor(0.5286, grad_fn=<DivBackward0>), tensor(0.5233, grad_fn=<DivBackward0>), tensor(0.5328, grad_fn=<DivBackward0>), tensor(0.5294, grad_fn=<DivBackward0>), tensor(0.5905, grad_fn=<DivBackward0>), tensor(0.6320, grad_fn=<DivBackward0>), tensor(0.5818, grad_fn=<DivBackward0>), tensor(0.6216, grad_fn=<DivBackward0>), tensor(0.5573, grad_fn=<DivBackward0>), tensor(0.6327, grad_fn=<DivBackward0>), tensor(0.6173, grad_fn=<DivBackward0>), tensor(0.5405, grad_fn=<DivBackward0>), tensor(0.5247, grad_fn=<DivBackward0>), tensor(0.6379, grad_fn=<DivBackward0>), tensor(0.5100, grad_fn=<DivBackward0>), tensor(0.5679, grad_fn=<DivBackward0>), tensor(0.5164, grad_fn=<DivBackward0>), tensor(0.5572, grad_fn=<DivBackward0>), tensor(0.5631, grad_fn=<DivBackward0>), tensor(0.6182, grad_fn=<DivBackward0>), tensor(0.5626, grad_fn=<DivBackward0>), tensor(0.4971, grad_fn=<DivBackward0>), tensor(0.5381, grad_fn=<DivBackward0>), tensor(0.5440, grad_fn=<DivBackward0>), tensor(0.5432, grad_fn=<DivBackward0>), tensor(0.5245, grad_fn=<DivBackward0>), tensor(0.6437, grad_fn=<DivBackward0>), tensor(0.5190, grad_fn=<DivBackward0>), tensor(0.6101, grad_fn=<DivBackward0>), tensor(0.5241, grad_fn=<DivBackward0>), tensor(0.6188, grad_fn=<DivBackward0>), tensor(0.5876, grad_fn=<DivBackward0>), tensor(0.5033, grad_fn=<DivBackward0>), tensor(0.5207, grad_fn=<DivBackward0>), tensor(0.4980, grad_fn=<DivBackward0>), tensor(0.5994, grad_fn=<DivBackward0>), tensor(0.5906, grad_fn=<DivBackward0>), tensor(0.5069, grad_fn=<DivBackward0>), tensor(0.5096, grad_fn=<DivBackward0>), tensor(0.5440, grad_fn=<DivBackward0>), tensor(0.5231, grad_fn=<DivBackward0>), tensor(0.5513, grad_fn=<DivBackward0>), tensor(0.6047, grad_fn=<DivBackward0>), tensor(0.5370, grad_fn=<DivBackward0>), tensor(0.5810, grad_fn=<DivBackward0>), tensor(0.6086, grad_fn=<DivBackward0>), tensor(0.6324, grad_fn=<DivBackward0>), tensor(0.5310, grad_fn=<DivBackward0>), tensor(0.5302, grad_fn=<DivBackward0>), tensor(0.5427, grad_fn=<DivBackward0>), tensor(0.5860, grad_fn=<DivBackward0>), tensor(0.5707, grad_fn=<DivBackward0>), tensor(0.5385, grad_fn=<DivBackward0>), tensor(0.5927, grad_fn=<DivBackward0>), tensor(0.5898, grad_fn=<DivBackward0>), tensor(0.5128, grad_fn=<DivBackward0>), tensor(0.5022, grad_fn=<DivBackward0>), tensor(0.5467, grad_fn=<DivBackward0>), tensor(0.6056, grad_fn=<DivBackward0>), tensor(0.6218, grad_fn=<DivBackward0>), tensor(0.5317, grad_fn=<DivBackward0>), tensor(0.5964, grad_fn=<DivBackward0>), tensor(0.5009, grad_fn=<DivBackward0>), tensor(0.5492, grad_fn=<DivBackward0>), tensor(0.5376, grad_fn=<DivBackward0>), tensor(0.5232, grad_fn=<DivBackward0>), tensor(0.5220, grad_fn=<DivBackward0>), tensor(0.5197, grad_fn=<DivBackward0>), tensor(0.6158, grad_fn=<DivBackward0>), tensor(0.6313, grad_fn=<DivBackward0>), tensor(0.5741, grad_fn=<DivBackward0>), tensor(0.5429, grad_fn=<DivBackward0>), tensor(0.5251, grad_fn=<DivBackward0>), tensor(0.4992, grad_fn=<DivBackward0>), tensor(0.5339, grad_fn=<DivBackward0>), tensor(0.5359, grad_fn=<DivBackward0>), tensor(0.5629, grad_fn=<DivBackward0>), tensor(0.5112, grad_fn=<DivBackward0>), tensor(0.5400, grad_fn=<DivBackward0>), tensor(0.5576, grad_fn=<DivBackward0>), tensor(0.5570, grad_fn=<DivBackward0>), tensor(0.5316, grad_fn=<DivBackward0>), tensor(0.5629, grad_fn=<DivBackward0>), tensor(0.6132, grad_fn=<DivBackward0>), tensor(0.5133, grad_fn=<DivBackward0>), tensor(0.5492, grad_fn=<DivBackward0>), tensor(0.5395, grad_fn=<DivBackward0>), tensor(0.5148, grad_fn=<DivBackward0>), tensor(0.6278, grad_fn=<DivBackward0>), tensor(0.6130, grad_fn=<DivBackward0>), tensor(0.5010, grad_fn=<DivBackward0>), tensor(0.5442, grad_fn=<DivBackward0>), tensor(0.5647, grad_fn=<DivBackward0>), tensor(0.4998, grad_fn=<DivBackward0>), tensor(0.5270, grad_fn=<DivBackward0>), tensor(0.5327, grad_fn=<DivBackward0>), tensor(0.5305, grad_fn=<DivBackward0>), tensor(0.5033, grad_fn=<DivBackward0>), tensor(0.6060, grad_fn=<DivBackward0>), tensor(0.5267, grad_fn=<DivBackward0>), tensor(0.5145, grad_fn=<DivBackward0>), tensor(0.6341, grad_fn=<DivBackward0>), tensor(0.5317, grad_fn=<DivBackward0>), tensor(0.5952, grad_fn=<DivBackward0>), tensor(0.5289, grad_fn=<DivBackward0>), tensor(0.5261, grad_fn=<DivBackward0>), tensor(0.6318, grad_fn=<DivBackward0>), tensor(0.5274, grad_fn=<DivBackward0>), tensor(0.5681, grad_fn=<DivBackward0>), tensor(0.5627, grad_fn=<DivBackward0>), tensor(0.5399, grad_fn=<DivBackward0>), tensor(0.6248, grad_fn=<DivBackward0>), tensor(0.5187, grad_fn=<DivBackward0>), tensor(0.5661, grad_fn=<DivBackward0>), tensor(0.5225, grad_fn=<DivBackward0>), tensor(0.5429, grad_fn=<DivBackward0>), tensor(0.5242, grad_fn=<DivBackward0>), tensor(0.5299, grad_fn=<DivBackward0>), tensor(0.4998, grad_fn=<DivBackward0>), tensor(0.5918, grad_fn=<DivBackward0>), tensor(0.6009, grad_fn=<DivBackward0>), tensor(0.5223, grad_fn=<DivBackward0>), tensor(0.6111, grad_fn=<DivBackward0>), tensor(0.5715, grad_fn=<DivBackward0>), tensor(0.5258, grad_fn=<DivBackward0>), tensor(0.5260, grad_fn=<DivBackward0>), tensor(0.5320, grad_fn=<DivBackward0>), tensor(0.5262, grad_fn=<DivBackward0>), tensor(0.6287, grad_fn=<DivBackward0>), tensor(0.5560, grad_fn=<DivBackward0>), tensor(0.6297, grad_fn=<DivBackward0>), tensor(0.5310, grad_fn=<DivBackward0>), tensor(0.5962, grad_fn=<DivBackward0>), tensor(0.6258, grad_fn=<DivBackward0>), tensor(0.5498, grad_fn=<DivBackward0>), tensor(0.5387, grad_fn=<DivBackward0>), tensor(0.5121, grad_fn=<DivBackward0>), tensor(0.5759, grad_fn=<DivBackward0>), tensor(0.6032, grad_fn=<DivBackward0>), tensor(0.5129, grad_fn=<DivBackward0>), tensor(0.5616, grad_fn=<DivBackward0>), tensor(0.5661, grad_fn=<DivBackward0>), tensor(0.5569, grad_fn=<DivBackward0>), tensor(0.5041, grad_fn=<DivBackward0>), tensor(0.5735, grad_fn=<DivBackward0>), tensor(0.5106, grad_fn=<DivBackward0>), tensor(0.5190, grad_fn=<DivBackward0>), tensor(0.5391, grad_fn=<DivBackward0>), tensor(0.5044, grad_fn=<DivBackward0>), tensor(0.5517, grad_fn=<DivBackward0>), tensor(0.5372, grad_fn=<DivBackward0>), tensor(0.5737, grad_fn=<DivBackward0>), tensor(0.5917, grad_fn=<DivBackward0>), tensor(0.5815, grad_fn=<DivBackward0>), tensor(0.5366, grad_fn=<DivBackward0>), tensor(0.4942, grad_fn=<DivBackward0>), tensor(0.6326, grad_fn=<DivBackward0>), tensor(0.5416, grad_fn=<DivBackward0>), tensor(0.5048, grad_fn=<DivBackward0>), tensor(0.5405, grad_fn=<DivBackward0>), tensor(0.5306, grad_fn=<DivBackward0>), tensor(0.5335, grad_fn=<DivBackward0>), tensor(0.6117, grad_fn=<DivBackward0>), tensor(0.5076, grad_fn=<DivBackward0>), tensor(0.5333, grad_fn=<DivBackward0>), tensor(0.5095, grad_fn=<DivBackward0>), tensor(0.5153, grad_fn=<DivBackward0>), tensor(0.5219, grad_fn=<DivBackward0>), tensor(0.5487, grad_fn=<DivBackward0>), tensor(0.6158, grad_fn=<DivBackward0>), tensor(0.5779, grad_fn=<DivBackward0>), tensor(0.5252, grad_fn=<DivBackward0>), tensor(0.5263, grad_fn=<DivBackward0>), tensor(0.5646, grad_fn=<DivBackward0>), tensor(0.5269, grad_fn=<DivBackward0>), tensor(0.5250, grad_fn=<DivBackward0>), tensor(0.5489, grad_fn=<DivBackward0>), tensor(0.5934, grad_fn=<DivBackward0>), tensor(0.5249, grad_fn=<DivBackward0>), tensor(0.5544, grad_fn=<DivBackward0>), tensor(0.5990, grad_fn=<DivBackward0>), tensor(0.5549, grad_fn=<DivBackward0>), tensor(0.5300, grad_fn=<DivBackward0>), tensor(0.5275, grad_fn=<DivBackward0>), tensor(0.5242, grad_fn=<DivBackward0>), tensor(0.5234, grad_fn=<DivBackward0>), tensor(0.6211, grad_fn=<DivBackward0>), tensor(0.5662, grad_fn=<DivBackward0>), tensor(0.5753, grad_fn=<DivBackward0>), tensor(0.5235, grad_fn=<DivBackward0>), tensor(0.5219, grad_fn=<DivBackward0>), tensor(0.4999, grad_fn=<DivBackward0>), tensor(0.5025, grad_fn=<DivBackward0>), tensor(0.5105, grad_fn=<DivBackward0>), tensor(0.5312, grad_fn=<DivBackward0>), tensor(0.6295, grad_fn=<DivBackward0>), tensor(0.5173, grad_fn=<DivBackward0>), tensor(0.5482, grad_fn=<DivBackward0>), tensor(0.5288, grad_fn=<DivBackward0>), tensor(0.5227, grad_fn=<DivBackward0>), tensor(0.5349, grad_fn=<DivBackward0>), tensor(0.6053, grad_fn=<DivBackward0>), tensor(0.5268, grad_fn=<DivBackward0>), tensor(0.5021, grad_fn=<DivBackward0>), tensor(0.5220, grad_fn=<DivBackward0>), tensor(0.5531, grad_fn=<DivBackward0>), tensor(0.5050, grad_fn=<DivBackward0>), tensor(0.5049, grad_fn=<DivBackward0>), tensor(0.6206, grad_fn=<DivBackward0>), tensor(0.5936, grad_fn=<DivBackward0>), tensor(0.6266, grad_fn=<DivBackward0>), tensor(0.5830, grad_fn=<DivBackward0>), tensor(0.5638, grad_fn=<DivBackward0>), tensor(0.5434, grad_fn=<DivBackward0>), tensor(0.5109, grad_fn=<DivBackward0>), tensor(0.5895, grad_fn=<DivBackward0>), tensor(0.5232, grad_fn=<DivBackward0>), tensor(0.5871, grad_fn=<DivBackward0>), tensor(0.6027, grad_fn=<DivBackward0>), tensor(0.4968, grad_fn=<DivBackward0>), tensor(0.5234, grad_fn=<DivBackward0>), tensor(0.6100, grad_fn=<DivBackward0>), tensor(0.5792, grad_fn=<DivBackward0>), tensor(0.5223, grad_fn=<DivBackward0>), tensor(0.6202, grad_fn=<DivBackward0>), tensor(0.5701, grad_fn=<DivBackward0>), tensor(0.5963, grad_fn=<DivBackward0>), tensor(0.6116, grad_fn=<DivBackward0>), tensor(0.5817, grad_fn=<DivBackward0>), tensor(0.5241, grad_fn=<DivBackward0>), tensor(0.5931, grad_fn=<DivBackward0>), tensor(0.5188, grad_fn=<DivBackward0>), tensor(0.5846, grad_fn=<DivBackward0>), tensor(0.5082, grad_fn=<DivBackward0>), tensor(0.6356, grad_fn=<DivBackward0>), tensor(0.6377, grad_fn=<DivBackward0>), tensor(0.5466, grad_fn=<DivBackward0>), tensor(0.6189, grad_fn=<DivBackward0>), tensor(0.5348, grad_fn=<DivBackward0>), tensor(0.5301, grad_fn=<DivBackward0>), tensor(0.5814, grad_fn=<DivBackward0>), tensor(0.5408, grad_fn=<DivBackward0>), tensor(0.5579, grad_fn=<DivBackward0>), tensor(0.6202, grad_fn=<DivBackward0>), tensor(0.5192, grad_fn=<DivBackward0>), tensor(0.5363, grad_fn=<DivBackward0>), tensor(0.5356, grad_fn=<DivBackward0>), tensor(0.6300, grad_fn=<DivBackward0>), tensor(0.5307, grad_fn=<DivBackward0>), tensor(0.5366, grad_fn=<DivBackward0>), tensor(0.5265, grad_fn=<DivBackward0>), tensor(0.5892, grad_fn=<DivBackward0>), tensor(0.6413, grad_fn=<DivBackward0>), tensor(0.5373, grad_fn=<DivBackward0>), tensor(0.5492, grad_fn=<DivBackward0>), tensor(0.5572, grad_fn=<DivBackward0>), tensor(0.5096, grad_fn=<DivBackward0>), tensor(0.4989, grad_fn=<DivBackward0>), tensor(0.6262, grad_fn=<DivBackward0>), tensor(0.5479, grad_fn=<DivBackward0>), tensor(0.5319, grad_fn=<DivBackward0>), tensor(0.5572, grad_fn=<DivBackward0>), tensor(0.5589, grad_fn=<DivBackward0>), tensor(0.5936, grad_fn=<DivBackward0>), tensor(0.5077, grad_fn=<DivBackward0>), tensor(0.5000, grad_fn=<DivBackward0>), tensor(0.5905, grad_fn=<DivBackward0>), tensor(0.5262, grad_fn=<DivBackward0>), tensor(0.5565, grad_fn=<DivBackward0>), tensor(0.5838, grad_fn=<DivBackward0>), tensor(0.5512, grad_fn=<DivBackward0>), tensor(0.5390, grad_fn=<DivBackward0>), tensor(0.6047, grad_fn=<DivBackward0>), tensor(0.5013, grad_fn=<DivBackward0>), tensor(0.5158, grad_fn=<DivBackward0>), tensor(0.5066, grad_fn=<DivBackward0>), tensor(0.5012, grad_fn=<DivBackward0>), tensor(0.5096, grad_fn=<DivBackward0>), tensor(0.5980, grad_fn=<DivBackward0>), tensor(0.5398, grad_fn=<DivBackward0>), tensor(0.6016, grad_fn=<DivBackward0>), tensor(0.5459, grad_fn=<DivBackward0>), tensor(0.5070, grad_fn=<DivBackward0>), tensor(0.5239, grad_fn=<DivBackward0>), tensor(0.5731, grad_fn=<DivBackward0>), tensor(0.6171, grad_fn=<DivBackward0>), tensor(0.5103, grad_fn=<DivBackward0>), tensor(0.5884, grad_fn=<DivBackward0>), tensor(0.5364, grad_fn=<DivBackward0>), tensor(0.6458, grad_fn=<DivBackward0>), tensor(0.5789, grad_fn=<DivBackward0>), tensor(0.5371, grad_fn=<DivBackward0>), tensor(0.5173, grad_fn=<DivBackward0>), tensor(0.4986, grad_fn=<DivBackward0>), tensor(0.5029, grad_fn=<DivBackward0>), tensor(0.5657, grad_fn=<DivBackward0>), tensor(0.6170, grad_fn=<DivBackward0>), tensor(0.5067, grad_fn=<DivBackward0>), tensor(0.5234, grad_fn=<DivBackward0>), tensor(0.6275, grad_fn=<DivBackward0>), tensor(0.5803, grad_fn=<DivBackward0>), tensor(0.5262, grad_fn=<DivBackward0>), tensor(0.5108, grad_fn=<DivBackward0>), tensor(0.5461, grad_fn=<DivBackward0>), tensor(0.5338, grad_fn=<DivBackward0>), tensor(0.5349, grad_fn=<DivBackward0>), tensor(0.5219, grad_fn=<DivBackward0>), tensor(0.6326, grad_fn=<DivBackward0>), tensor(0.4999, grad_fn=<DivBackward0>), tensor(0.5451, grad_fn=<DivBackward0>), tensor(0.6047, grad_fn=<DivBackward0>), tensor(0.5930, grad_fn=<DivBackward0>), tensor(0.5252, grad_fn=<DivBackward0>), tensor(0.6155, grad_fn=<DivBackward0>), tensor(0.6015, grad_fn=<DivBackward0>), tensor(0.6390, grad_fn=<DivBackward0>), tensor(0.6195, grad_fn=<DivBackward0>), tensor(0.5285, grad_fn=<DivBackward0>), tensor(0.5954, grad_fn=<DivBackward0>), tensor(0.6058, grad_fn=<DivBackward0>), tensor(0.6118, grad_fn=<DivBackward0>), tensor(0.5110, grad_fn=<DivBackward0>), tensor(0.5572, grad_fn=<DivBackward0>), tensor(0.6395, grad_fn=<DivBackward0>), tensor(0.5113, grad_fn=<DivBackward0>), tensor(0.5129, grad_fn=<DivBackward0>), tensor(0.5301, grad_fn=<DivBackward0>), tensor(0.5591, grad_fn=<DivBackward0>), tensor(0.6279, grad_fn=<DivBackward0>), tensor(0.5638, grad_fn=<DivBackward0>), tensor(0.6445, grad_fn=<DivBackward0>), tensor(0.6131, grad_fn=<DivBackward0>), tensor(0.5735, grad_fn=<DivBackward0>), tensor(0.5119, grad_fn=<DivBackward0>), tensor(0.4995, grad_fn=<DivBackward0>), tensor(0.6159, grad_fn=<DivBackward0>), tensor(0.5404, grad_fn=<DivBackward0>), tensor(0.5233, grad_fn=<DivBackward0>), tensor(0.5178, grad_fn=<DivBackward0>), tensor(0.5229, grad_fn=<DivBackward0>), tensor(0.5165, grad_fn=<DivBackward0>), tensor(0.5387, grad_fn=<DivBackward0>), tensor(0.5509, grad_fn=<DivBackward0>), tensor(0.5796, grad_fn=<DivBackward0>), tensor(0.5066, grad_fn=<DivBackward0>), tensor(0.6091, grad_fn=<DivBackward0>), tensor(0.5590, grad_fn=<DivBackward0>), tensor(0.5590, grad_fn=<DivBackward0>), tensor(0.5464, grad_fn=<DivBackward0>), tensor(0.5618, grad_fn=<DivBackward0>), tensor(0.5779, grad_fn=<DivBackward0>), tensor(0.5381, grad_fn=<DivBackward0>), tensor(0.5600, grad_fn=<DivBackward0>), tensor(0.5792, grad_fn=<DivBackward0>), tensor(0.5388, grad_fn=<DivBackward0>), tensor(0.5384, grad_fn=<DivBackward0>), tensor(0.5255, grad_fn=<DivBackward0>), tensor(0.6008, grad_fn=<DivBackward0>), tensor(0.6070, grad_fn=<DivBackward0>), tensor(0.5763, grad_fn=<DivBackward0>), tensor(0.5340, grad_fn=<DivBackward0>), tensor(0.5473, grad_fn=<DivBackward0>), tensor(0.5937, grad_fn=<DivBackward0>), tensor(0.5100, grad_fn=<DivBackward0>), tensor(0.5383, grad_fn=<DivBackward0>), tensor(0.5498, grad_fn=<DivBackward0>), tensor(0.6318, grad_fn=<DivBackward0>), tensor(0.6351, grad_fn=<DivBackward0>), tensor(0.5209, grad_fn=<DivBackward0>), tensor(0.6436, grad_fn=<DivBackward0>), tensor(0.5336, grad_fn=<DivBackward0>), tensor(0.5317, grad_fn=<DivBackward0>), tensor(0.5226, grad_fn=<DivBackward0>), tensor(0.5418, grad_fn=<DivBackward0>), tensor(0.5122, grad_fn=<DivBackward0>), tensor(0.5287, grad_fn=<DivBackward0>), tensor(0.5268, grad_fn=<DivBackward0>), tensor(0.6307, grad_fn=<DivBackward0>), tensor(0.5129, grad_fn=<DivBackward0>), tensor(0.6161, grad_fn=<DivBackward0>), tensor(0.5888, grad_fn=<DivBackward0>), tensor(0.5090, grad_fn=<DivBackward0>), tensor(0.5148, grad_fn=<DivBackward0>), tensor(0.5451, grad_fn=<DivBackward0>), tensor(0.5416, grad_fn=<DivBackward0>), tensor(0.5522, grad_fn=<DivBackward0>), tensor(0.6329, grad_fn=<DivBackward0>), tensor(0.5452, grad_fn=<DivBackward0>), tensor(0.6380, grad_fn=<DivBackward0>), tensor(0.5329, grad_fn=<DivBackward0>), tensor(0.5646, grad_fn=<DivBackward0>), tensor(0.5126, grad_fn=<DivBackward0>), tensor(0.5524, grad_fn=<DivBackward0>), tensor(0.5978, grad_fn=<DivBackward0>), tensor(0.6421, grad_fn=<DivBackward0>), tensor(0.4913, grad_fn=<DivBackward0>), tensor(0.5029, grad_fn=<DivBackward0>), tensor(0.5678, grad_fn=<DivBackward0>), tensor(0.5377, grad_fn=<DivBackward0>), tensor(0.5527, grad_fn=<DivBackward0>), tensor(0.5509, grad_fn=<DivBackward0>), tensor(0.5555, grad_fn=<DivBackward0>), tensor(0.5347, grad_fn=<DivBackward0>), tensor(0.5992, grad_fn=<DivBackward0>), tensor(0.5041, grad_fn=<DivBackward0>), tensor(0.5450, grad_fn=<DivBackward0>), tensor(0.5411, grad_fn=<DivBackward0>), tensor(0.5247, grad_fn=<DivBackward0>), tensor(0.5692, grad_fn=<DivBackward0>), tensor(0.4978, grad_fn=<DivBackward0>), tensor(0.5537, grad_fn=<DivBackward0>), tensor(0.5512, grad_fn=<DivBackward0>), tensor(0.6321, grad_fn=<DivBackward0>), tensor(0.6081, grad_fn=<DivBackward0>), tensor(0.5340, grad_fn=<DivBackward0>), tensor(0.6110, grad_fn=<DivBackward0>), tensor(0.6144, grad_fn=<DivBackward0>), tensor(0.6049, grad_fn=<DivBackward0>), tensor(0.5473, grad_fn=<DivBackward0>), tensor(0.5118, grad_fn=<DivBackward0>), tensor(0.5270, grad_fn=<DivBackward0>), tensor(0.5538, grad_fn=<DivBackward0>), tensor(0.5904, grad_fn=<DivBackward0>), tensor(0.5914, grad_fn=<DivBackward0>), tensor(0.5351, grad_fn=<DivBackward0>), tensor(0.5653, grad_fn=<DivBackward0>), tensor(0.5296, grad_fn=<DivBackward0>), tensor(0.5236, grad_fn=<DivBackward0>), tensor(0.5045, grad_fn=<DivBackward0>), tensor(0.5389, grad_fn=<DivBackward0>), tensor(0.5391, grad_fn=<DivBackward0>), tensor(0.5321, grad_fn=<DivBackward0>), tensor(0.5540, grad_fn=<DivBackward0>), tensor(0.6268, grad_fn=<DivBackward0>), tensor(0.5238, grad_fn=<DivBackward0>), tensor(0.5418, grad_fn=<DivBackward0>), tensor(0.5287, grad_fn=<DivBackward0>), tensor(0.6357, grad_fn=<DivBackward0>), tensor(0.5925, grad_fn=<DivBackward0>), tensor(0.5916, grad_fn=<DivBackward0>), tensor(0.6284, grad_fn=<DivBackward0>), tensor(0.6252, grad_fn=<DivBackward0>), tensor(0.5270, grad_fn=<DivBackward0>), tensor(0.5293, grad_fn=<DivBackward0>), tensor(0.6029, grad_fn=<DivBackward0>), tensor(0.5037, grad_fn=<DivBackward0>), tensor(0.5823, grad_fn=<DivBackward0>), tensor(0.6189, grad_fn=<DivBackward0>), tensor(0.5254, grad_fn=<DivBackward0>), tensor(0.5720, grad_fn=<DivBackward0>), tensor(0.6323, grad_fn=<DivBackward0>), tensor(0.5575, grad_fn=<DivBackward0>), tensor(0.6108, grad_fn=<DivBackward0>), tensor(0.5339, grad_fn=<DivBackward0>), tensor(0.5640, grad_fn=<DivBackward0>), tensor(0.6423, grad_fn=<DivBackward0>), tensor(0.5413, grad_fn=<DivBackward0>), tensor(0.6370, grad_fn=<DivBackward0>), tensor(0.5047, grad_fn=<DivBackward0>), tensor(0.5185, grad_fn=<DivBackward0>), tensor(0.5520, grad_fn=<DivBackward0>), tensor(0.5252, grad_fn=<DivBackward0>), tensor(0.5537, grad_fn=<DivBackward0>), tensor(0.6194, grad_fn=<DivBackward0>), tensor(0.6234, grad_fn=<DivBackward0>), tensor(0.5986, grad_fn=<DivBackward0>), tensor(0.5876, grad_fn=<DivBackward0>), tensor(0.5260, grad_fn=<DivBackward0>), tensor(0.5938, grad_fn=<DivBackward0>), tensor(0.5215, grad_fn=<DivBackward0>), tensor(0.5923, grad_fn=<DivBackward0>), tensor(0.5825, grad_fn=<DivBackward0>), tensor(0.5031, grad_fn=<DivBackward0>), tensor(0.5559, grad_fn=<DivBackward0>), tensor(0.5986, grad_fn=<DivBackward0>), tensor(0.5461, grad_fn=<DivBackward0>), tensor(0.5764, grad_fn=<DivBackward0>), tensor(0.5281, grad_fn=<DivBackward0>), tensor(0.5321, grad_fn=<DivBackward0>), tensor(0.5574, grad_fn=<DivBackward0>), tensor(0.6286, grad_fn=<DivBackward0>), tensor(0.5000, grad_fn=<DivBackward0>), tensor(0.5388, grad_fn=<DivBackward0>), tensor(0.5071, grad_fn=<DivBackward0>), tensor(0.5311, grad_fn=<DivBackward0>), tensor(0.5216, grad_fn=<DivBackward0>), tensor(0.5715, grad_fn=<DivBackward0>), tensor(0.6140, grad_fn=<DivBackward0>), tensor(0.5445, grad_fn=<DivBackward0>), tensor(0.6116, grad_fn=<DivBackward0>), tensor(0.6097, grad_fn=<DivBackward0>), tensor(0.6027, grad_fn=<DivBackward0>), tensor(0.4998, grad_fn=<DivBackward0>), tensor(0.6033, grad_fn=<DivBackward0>), tensor(0.5199, grad_fn=<DivBackward0>), tensor(0.5363, grad_fn=<DivBackward0>), tensor(0.6221, grad_fn=<DivBackward0>), tensor(0.6332, grad_fn=<DivBackward0>), tensor(0.5390, grad_fn=<DivBackward0>), tensor(0.5289, grad_fn=<DivBackward0>), tensor(0.4988, grad_fn=<DivBackward0>), tensor(0.5745, grad_fn=<DivBackward0>), tensor(0.5314, grad_fn=<DivBackward0>), tensor(0.5088, grad_fn=<DivBackward0>), tensor(0.6342, grad_fn=<DivBackward0>), tensor(0.5332, grad_fn=<DivBackward0>), tensor(0.5117, grad_fn=<DivBackward0>), tensor(0.6401, grad_fn=<DivBackward0>), tensor(0.5387, grad_fn=<DivBackward0>), tensor(0.5966, grad_fn=<DivBackward0>), tensor(0.5646, grad_fn=<DivBackward0>), tensor(0.5121, grad_fn=<DivBackward0>), tensor(0.5799, grad_fn=<DivBackward0>), tensor(0.5456, grad_fn=<DivBackward0>), tensor(0.6320, grad_fn=<DivBackward0>), tensor(0.5207, grad_fn=<DivBackward0>), tensor(0.5578, grad_fn=<DivBackward0>), tensor(0.5321, grad_fn=<DivBackward0>), tensor(0.5616, grad_fn=<DivBackward0>), tensor(0.5917, grad_fn=<DivBackward0>), tensor(0.5775, grad_fn=<DivBackward0>), tensor(0.5414, grad_fn=<DivBackward0>), tensor(0.5383, grad_fn=<DivBackward0>), tensor(0.5152, grad_fn=<DivBackward0>), tensor(0.6106, grad_fn=<DivBackward0>), tensor(0.6268, grad_fn=<DivBackward0>), tensor(0.6255, grad_fn=<DivBackward0>), tensor(0.5547, grad_fn=<DivBackward0>), tensor(0.5517, grad_fn=<DivBackward0>), tensor(0.5457, grad_fn=<DivBackward0>), tensor(0.5421, grad_fn=<DivBackward0>), tensor(0.5416, grad_fn=<DivBackward0>), tensor(0.5334, grad_fn=<DivBackward0>), tensor(0.5258, grad_fn=<DivBackward0>), tensor(0.5115, grad_fn=<DivBackward0>), tensor(0.5340, grad_fn=<DivBackward0>), tensor(0.5487, grad_fn=<DivBackward0>), tensor(0.5082, grad_fn=<DivBackward0>), tensor(0.5281, grad_fn=<DivBackward0>), tensor(0.5258, grad_fn=<DivBackward0>), tensor(0.5904, grad_fn=<DivBackward0>), tensor(0.5056, grad_fn=<DivBackward0>), tensor(0.5083, grad_fn=<DivBackward0>), tensor(0.5448, grad_fn=<DivBackward0>), tensor(0.5158, grad_fn=<DivBackward0>), tensor(0.5193, grad_fn=<DivBackward0>), tensor(0.6038, grad_fn=<DivBackward0>), tensor(0.5734, grad_fn=<DivBackward0>), tensor(0.5438, grad_fn=<DivBackward0>), tensor(0.5315, grad_fn=<DivBackward0>), tensor(0.5387, grad_fn=<DivBackward0>), tensor(0.5504, grad_fn=<DivBackward0>), tensor(0.5339, grad_fn=<DivBackward0>), tensor(0.6157, grad_fn=<DivBackward0>), tensor(0.5279, grad_fn=<DivBackward0>), tensor(0.5306, grad_fn=<DivBackward0>), tensor(0.5386, grad_fn=<DivBackward0>), tensor(0.6395, grad_fn=<DivBackward0>), tensor(0.5445, grad_fn=<DivBackward0>), tensor(0.6413, grad_fn=<DivBackward0>), tensor(0.5980, grad_fn=<DivBackward0>), tensor(0.5944, grad_fn=<DivBackward0>), tensor(0.5379, grad_fn=<DivBackward0>), tensor(0.5921, grad_fn=<DivBackward0>), tensor(0.5269, grad_fn=<DivBackward0>), tensor(0.5845, grad_fn=<DivBackward0>), tensor(0.5330, grad_fn=<DivBackward0>), tensor(0.5366, grad_fn=<DivBackward0>), tensor(0.5352, grad_fn=<DivBackward0>), tensor(0.5676, grad_fn=<DivBackward0>), tensor(0.5541, grad_fn=<DivBackward0>), tensor(0.5258, grad_fn=<DivBackward0>), tensor(0.6020, grad_fn=<DivBackward0>), tensor(0.5281, grad_fn=<DivBackward0>), tensor(0.4999, grad_fn=<DivBackward0>), tensor(0.5995, grad_fn=<DivBackward0>), tensor(0.4998, grad_fn=<DivBackward0>), tensor(0.6291, grad_fn=<DivBackward0>), tensor(0.6096, grad_fn=<DivBackward0>), tensor(0.6371, grad_fn=<DivBackward0>), tensor(0.6211, grad_fn=<DivBackward0>), tensor(0.5093, grad_fn=<DivBackward0>), tensor(0.6144, grad_fn=<DivBackward0>), tensor(0.5395, grad_fn=<DivBackward0>), tensor(0.5678, grad_fn=<DivBackward0>), tensor(0.5403, grad_fn=<DivBackward0>), tensor(0.5617, grad_fn=<DivBackward0>), tensor(0.6284, grad_fn=<DivBackward0>), tensor(0.5300, grad_fn=<DivBackward0>), tensor(0.6032, grad_fn=<DivBackward0>), tensor(0.5268, grad_fn=<DivBackward0>), tensor(0.5434, grad_fn=<DivBackward0>), tensor(0.5995, grad_fn=<DivBackward0>), tensor(0.5228, grad_fn=<DivBackward0>), tensor(0.5429, grad_fn=<DivBackward0>), tensor(0.6361, grad_fn=<DivBackward0>), tensor(0.5027, grad_fn=<DivBackward0>), tensor(0.5011, grad_fn=<DivBackward0>), tensor(0.5154, grad_fn=<DivBackward0>), tensor(0.5522, grad_fn=<DivBackward0>), tensor(0.5297, grad_fn=<DivBackward0>), tensor(0.6301, grad_fn=<DivBackward0>), tensor(0.5012, grad_fn=<DivBackward0>), tensor(0.5247, grad_fn=<DivBackward0>), tensor(0.5160, grad_fn=<DivBackward0>), tensor(0.6387, grad_fn=<DivBackward0>), tensor(0.5682, grad_fn=<DivBackward0>), tensor(0.5724, grad_fn=<DivBackward0>), tensor(0.6365, grad_fn=<DivBackward0>), tensor(0.5360, grad_fn=<DivBackward0>), tensor(0.6042, grad_fn=<DivBackward0>), tensor(0.5720, grad_fn=<DivBackward0>), tensor(0.6422, grad_fn=<DivBackward0>), tensor(0.5780, grad_fn=<DivBackward0>), tensor(0.5504, grad_fn=<DivBackward0>), tensor(0.5037, grad_fn=<DivBackward0>), tensor(0.5442, grad_fn=<DivBackward0>), tensor(0.5007, grad_fn=<DivBackward0>), tensor(0.5542, grad_fn=<DivBackward0>), tensor(0.6110, grad_fn=<DivBackward0>), tensor(0.5397, grad_fn=<DivBackward0>), tensor(0.5424, grad_fn=<DivBackward0>), tensor(0.5173, grad_fn=<DivBackward0>), tensor(0.6041, grad_fn=<DivBackward0>), tensor(0.4772, grad_fn=<DivBackward0>), tensor(0.4808, grad_fn=<DivBackward0>), tensor(0.5866, grad_fn=<DivBackward0>), tensor(0.5431, grad_fn=<DivBackward0>), tensor(0.5305, grad_fn=<DivBackward0>), tensor(0.6156, grad_fn=<DivBackward0>), tensor(0.5591, grad_fn=<DivBackward0>), tensor(0.5319, grad_fn=<DivBackward0>), tensor(0.5203, grad_fn=<DivBackward0>), tensor(0.5339, grad_fn=<DivBackward0>), tensor(0.5987, grad_fn=<DivBackward0>), tensor(0.5617, grad_fn=<DivBackward0>), tensor(0.5607, grad_fn=<DivBackward0>), tensor(0.5724, grad_fn=<DivBackward0>), tensor(0.5356, grad_fn=<DivBackward0>), tensor(0.5208, grad_fn=<DivBackward0>), tensor(0.5166, grad_fn=<DivBackward0>), tensor(0.6012, grad_fn=<DivBackward0>), tensor(0.6337, grad_fn=<DivBackward0>), tensor(0.6307, grad_fn=<DivBackward0>), tensor(0.5259, grad_fn=<DivBackward0>), tensor(0.5562, grad_fn=<DivBackward0>), tensor(0.5982, grad_fn=<DivBackward0>), tensor(0.6057, grad_fn=<DivBackward0>), tensor(0.5377, grad_fn=<DivBackward0>), tensor(0.5208, grad_fn=<DivBackward0>), tensor(0.5201, grad_fn=<DivBackward0>), tensor(0.5824, grad_fn=<DivBackward0>), tensor(0.6051, grad_fn=<DivBackward0>), tensor(0.5363, grad_fn=<DivBackward0>), tensor(0.5609, grad_fn=<DivBackward0>), tensor(0.5734, grad_fn=<DivBackward0>), tensor(0.5812, grad_fn=<DivBackward0>), tensor(0.5383, grad_fn=<DivBackward0>), tensor(0.6279, grad_fn=<DivBackward0>), tensor(0.5999, grad_fn=<DivBackward0>), tensor(0.5239, grad_fn=<DivBackward0>), tensor(0.5403, grad_fn=<DivBackward0>), tensor(0.5370, grad_fn=<DivBackward0>), tensor(0.5940, grad_fn=<DivBackward0>), tensor(0.6158, grad_fn=<DivBackward0>), tensor(0.5388, grad_fn=<DivBackward0>), tensor(0.5111, grad_fn=<DivBackward0>), tensor(0.5512, grad_fn=<DivBackward0>), tensor(0.6131, grad_fn=<DivBackward0>), tensor(0.5189, grad_fn=<DivBackward0>), tensor(0.5305, grad_fn=<DivBackward0>), tensor(0.6286, grad_fn=<DivBackward0>), tensor(0.5301, grad_fn=<DivBackward0>), tensor(0.5467, grad_fn=<DivBackward0>), tensor(0.5715, grad_fn=<DivBackward0>), tensor(0.5042, grad_fn=<DivBackward0>), tensor(0.5286, grad_fn=<DivBackward0>), tensor(0.6143, grad_fn=<DivBackward0>), tensor(0.5790, grad_fn=<DivBackward0>), tensor(0.5125, grad_fn=<DivBackward0>), tensor(0.5389, grad_fn=<DivBackward0>), tensor(0.6041, grad_fn=<DivBackward0>), tensor(0.5030, grad_fn=<DivBackward0>), tensor(0.5842, grad_fn=<DivBackward0>), tensor(0.5271, grad_fn=<DivBackward0>), tensor(0.4998, grad_fn=<DivBackward0>), tensor(0.6087, grad_fn=<DivBackward0>), tensor(0.6186, grad_fn=<DivBackward0>), tensor(0.5713, grad_fn=<DivBackward0>), tensor(0.5821, grad_fn=<DivBackward0>), tensor(0.5253, grad_fn=<DivBackward0>), tensor(0.5704, grad_fn=<DivBackward0>), tensor(0.5293, grad_fn=<DivBackward0>), tensor(0.5343, grad_fn=<DivBackward0>), tensor(0.5565, grad_fn=<DivBackward0>), tensor(0.5412, grad_fn=<DivBackward0>), tensor(0.5299, grad_fn=<DivBackward0>), tensor(0.5259, grad_fn=<DivBackward0>), tensor(0.5134, grad_fn=<DivBackward0>), tensor(0.5210, grad_fn=<DivBackward0>), tensor(0.5233, grad_fn=<DivBackward0>), tensor(0.4873, grad_fn=<DivBackward0>), tensor(0.5600, grad_fn=<DivBackward0>), tensor(0.5815, grad_fn=<DivBackward0>), tensor(0.5323, grad_fn=<DivBackward0>), tensor(0.5052, grad_fn=<DivBackward0>), tensor(0.5227, grad_fn=<DivBackward0>), tensor(0.5023, grad_fn=<DivBackward0>), tensor(0.6365, grad_fn=<DivBackward0>), tensor(0.5957, grad_fn=<DivBackward0>), tensor(0.5391, grad_fn=<DivBackward0>), tensor(0.5060, grad_fn=<DivBackward0>), tensor(0.5782, grad_fn=<DivBackward0>), tensor(0.5614, grad_fn=<DivBackward0>), tensor(0.5945, grad_fn=<DivBackward0>), tensor(0.4999, grad_fn=<DivBackward0>), tensor(0.5157, grad_fn=<DivBackward0>), tensor(0.5379, grad_fn=<DivBackward0>), tensor(0.5973, grad_fn=<DivBackward0>), tensor(0.5578, grad_fn=<DivBackward0>), tensor(0.5438, grad_fn=<DivBackward0>), tensor(0.5340, grad_fn=<DivBackward0>), tensor(0.5277, grad_fn=<DivBackward0>), tensor(0.5661, grad_fn=<DivBackward0>), tensor(0.5442, grad_fn=<DivBackward0>), tensor(0.6194, grad_fn=<DivBackward0>), tensor(0.5413, grad_fn=<DivBackward0>), tensor(0.4998, grad_fn=<DivBackward0>), tensor(0.6219, grad_fn=<DivBackward0>), tensor(0.5539, grad_fn=<DivBackward0>), tensor(0.5306, grad_fn=<DivBackward0>), tensor(0.6306, grad_fn=<DivBackward0>), tensor(0.6298, grad_fn=<DivBackward0>), tensor(0.6419, grad_fn=<DivBackward0>), tensor(0.4999, grad_fn=<DivBackward0>), tensor(0.6110, grad_fn=<DivBackward0>), tensor(0.5284, grad_fn=<DivBackward0>), tensor(0.5020, grad_fn=<DivBackward0>), tensor(0.6124, grad_fn=<DivBackward0>), tensor(0.5373, grad_fn=<DivBackward0>), tensor(0.5056, grad_fn=<DivBackward0>), tensor(0.5742, grad_fn=<DivBackward0>), tensor(0.5031, grad_fn=<DivBackward0>), tensor(0.5330, grad_fn=<DivBackward0>), tensor(0.5605, grad_fn=<DivBackward0>), tensor(0.6049, grad_fn=<DivBackward0>), tensor(0.5474, grad_fn=<DivBackward0>), tensor(0.5282, grad_fn=<DivBackward0>), tensor(0.5298, grad_fn=<DivBackward0>), tensor(0.5338, grad_fn=<DivBackward0>), tensor(0.5440, grad_fn=<DivBackward0>), tensor(0.6089, grad_fn=<DivBackward0>), tensor(0.5736, grad_fn=<DivBackward0>), tensor(0.5447, grad_fn=<DivBackward0>), tensor(0.6174, grad_fn=<DivBackward0>), tensor(0.6001, grad_fn=<DivBackward0>), tensor(0.5554, grad_fn=<DivBackward0>), tensor(0.6252, grad_fn=<DivBackward0>), tensor(0.5496, grad_fn=<DivBackward0>), tensor(0.5030, grad_fn=<DivBackward0>), tensor(0.5151, grad_fn=<DivBackward0>), tensor(0.5306, grad_fn=<DivBackward0>), tensor(0.5312, grad_fn=<DivBackward0>), tensor(0.5331, grad_fn=<DivBackward0>), tensor(0.5136, grad_fn=<DivBackward0>), tensor(0.5938, grad_fn=<DivBackward0>), tensor(0.5105, grad_fn=<DivBackward0>)]\n",
      "Dataset: BBBP Method: gstar, t-statistic: 15.660999378545085, p-value: 6.478748520904785e-53\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "dataset_name = \"BBBP\"\n",
    "#with open(f\"{dataset_name}_hfid_results.pkl\", \"rb\") as file:\n",
    "with open(\"BBBP_Gstarx_hfid.pkl\", \"rb\") as file:\n",
    "    t = pickle.load(file)\n",
    "# Perform t-test between ESPAM and other methods\n",
    "#with open(f\"{dataset_name}_ESPAM_results_{l}.pkl\", \"rb\") as file:\n",
    "#    espam_values = pickle.load(file)\n",
    "espam_values = list(map(lambda x: x.cpu().detach().numpy(), hfid_val['ESPAM']))\n",
    "results = {}\n",
    "print(hfid_val[\"ESPAM\"])\n",
    "for method, values in t.items():\n",
    "    if method != 'ESPAM':\n",
    "        t_stat, p_value = ttest_ind(espam_values, list(map(lambda x: x.cpu().detach().numpy(),values)))\n",
    "        results[method] = {'t_stat': t_stat, 'p_value': p_value}\n",
    "\n",
    "# Print the results\n",
    "for method, result in results.items():\n",
    "    print(f\"Dataset: {dataset_name} Method: {method}, t-statistic: {result['t_stat']}, p-value: {result['p_value']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_singularity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
